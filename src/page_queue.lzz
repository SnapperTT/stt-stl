#define STT_STT_NOCOPY(X) \
private:								\
	X(const X& other);					\
	X& operator =(const X & other);		\
public:	

#hdr
namespace stt {
	template<typename T, typename P>
	struct pageQueueImpl;
	
	template <typename T>
	using pageQueue = pageQueueImpl<T,pageU>;
	}

#define STT_PAGEQUEUE_MVSEM pageQueueImpl&&
#end

#src
#end

namespace stt {	
	template<typename T, typename P>
	struct pageQueueImpl {
		// Purpose: a thin std::vector replacement with discontigious storage of fixed-size blocks
		P* head;
		P* tail;
		
		struct iterator {
			T* ptr;
			T* localEnd;
			P* currentPage;
			
			void init(P* page) {
				currentPage = page;
				if (currentPage) {
					ptr = pageQueueImpl::pagePtr(currentPage);
					localEnd = &ptr[currentPage->ph.localSize];
					}
				else {
					ptr = NULL;
					localEnd = NULL;
					}
				}
			
			inline void incr() {
				if (ptr) // do not increment a null pointer
					ptr++;
				while (ptr == localEnd && currentPage) // if we are at the end of a page then increment to the next non-empty page
					incr_nonInline();
				}
				
			void incr_nonInline() {
				currentPage = (P*) currentPage->ph.next;
				if (currentPage) {
					ptr = pageQueueImpl::pagePtr(currentPage);
					localEnd = &ptr[currentPage->ph.localSize];
					}
				else {
					ptr = NULL;
					localEnd = NULL;
					}
				}
				
			inline typename pageQueueImpl<T,P>::iterator& operator++() {
				incr();
				return *this;
				}
				
			inline bool operator!=(const iterator & other) const { return ptr != other.ptr; }
			inline T operator* () { return *ptr; }
			};
		
		//////////////////////////////////////////////////////////////////////////
		inline pageQueueImpl () : head(NULL), tail(NULL) {}
		~pageQueueImpl() { clear(); }
		
		// pageQueues cannot be copied, only moved
		// move assign and move construct are needed for std::swap auto implementation
		inline void move_impl(STT_PAGEQUEUE_MVSEM other) { head = other.head; tail = other.tail; other.head = NULL; other.tail = NULL; }
		inline pageQueueImpl(STT_PAGEQUEUE_MVSEM other) { move_impl(std::move(other)); }
		inline pageQueueImpl<T,P>& operator= (STT_PAGEQUEUE_MVSEM other) { clear(); move_impl(std::move(other)); return *this; }
		STT_STT_NOCOPY(pageQueueImpl)
		
		// Allocators/deallocators go here
		static P* allocPage () {
			P* p = ThreadSafePageAllocatorTemplates::allocGeneric<P>();
			p->initHeader();
			return p;
			}
		static P* allocPages (const uint32_t nPages) {
			if (nPages == 0) return NULL;
			P* store[nPages];
			ThreadSafePageAllocatorTemplates::allocGenericBatch<P>(&store[0], nPages);
			return pageHeader::buildList((pageHeader**) &store[0], nPages);
			}
		static void freePage(P* page) {
			ThreadSafePageAllocatorTemplates::freeGeneric<P>(page);
			}
		static void freePagesList(P* pageList) {
			ThreadSafePageAllocatorTemplates::freeGenericList<P>(pageList);
			}
			
		// psuedo-private methods
		void extendTailIfRequired() {
			if (!tail || tail->ph.localSize >= pageLocalCapacity())
				extendTail();
			}
		
		void extendTail () {
			if (!tail) {
				head = allocPage();
				tail = head;
				return;
				}
			if (!tail->ph.next)
				tail->ph.next = (pageHeader*) allocPage();
			tail = (P*) tail->ph.next;
			}
		
		P* trueTail() const {
			// returns the true end of the linked list
			P* t = tail;
			if (!t) return t;
			while (t->ph.next)
				t = (P*) t->ph.next;
			return t;
			}
		
		// capacity
		static STT_CONSTEXPR__size_t pageLocalCapacity()         { return P::capacity() / sizeof(T);  }
		static STT_CONSTEXPR__T* pagePtr(P* const p)             { return (T*) &p->_data[STT_PAGE_HEADER_SIZE]; }
		static const STT_CONSTEXPR__T* pagePtr(const P* const p) { return (const T*) &p->_data[STT_PAGE_HEADER_SIZE]; }
				
		inline uint32_t size() const { return head ? head->ph.totalSize : 0; }
		uint32_t numPages () const { return head ? head->ph.listLength() : 0; }
		
		
		// std::vector like stuff goes here:
		void clear() {
			if constexpr(std::is_trivially_destructible<T>::value) {
				// we don't need to invoke destructors so we can just throw away the linked list
				if (head) {
					head->ph.cachedWorkingEnd = (pageHeader*) trueTail();
					freePagesList(head);
					}
				}
			else {
				// we need to itterate through the linked list and destroy every object
				P* w = head;
				while (w) {
					P* t = w;
					w = (P*) w->ph.next;
					call_destructors_for_page(t);
					freePage(t);
					}
				}
			head = NULL;
			tail = NULL;
			}
			
		static void call_destructors_for_page(P* t) {
			T* arr = pagePtr(t);
			const uint32_t sz = t->ph.localSize;
			for (uint32_t i = 0; i < sz; ++i)
				arr[i].~T();
			}
			
		void clearKeepingFirstPage() {
			// Clears the pageQueue but keeps the first page
			if (head && head->next) {
				pageQueueImpl tmp;
				tmp.head = head->next;
				tmp.head->ph.cachedWorkingEnd = tail;
				tmp.tail = tail;
				tmp.clear();
				head->ph.next = NULL;
				tail = head; 
				if constexpr(!std::is_trivially_destructible<T>::value)
					call_destructors_for_page(head);
				head->ph.localSize = 0;
				head->ph.totalSize = 0;
				}
			}
		
		void swap(pageQueueImpl& other) {
			std::swap(head, other.head);
			std::swap(tail, other.tail);
			}
		
		void concatenate(STT_PAGEQUEUE_MVSEM other) {
			// transfers the other queue to the end of this
			if (!other.head)
				return;
			if (tail) {
				tail->ph.next = (pageHeader*) other.head;
				tail = other.tail;
				}
			else {
				head = other.head;
				tail = other.tail;
				}
			other.head = NULL;
			other.tail = NULL;
			}
		
		inline void reserve(const uint32_t sz) {
			// no-op
			// TBD - allocates pages and links them. Tail is set to the push_back write-head but trueTail() is the end of allocated storage
			if (sz <= size()) return;
			if (tail)
				if (tail->ph.next)
					return; // pages are already preallocated
			
			//                   needed          avaliable in tail page
			const int32_t want = (sz - size()) - (pageLocalCapacity() - tail->ph.localSize);
			if (want <= 0) return; // already capacity avaliable
			uint32_t nPagesToAllocate = want/pageLocalCapacity();
			tail->ph.next = allocPages(nPagesToAllocate);
			}
		
		inline T* push_back(const T& t) {
			extendTailIfRequired();
			T* r = new (&(pageQueueImpl::pagePtr(tail)[tail->ph.localSize])) T(t);
			tail->ph.localSize++;
			head->ph.totalSize++;
			return r;
			}
		
		inline T* push_back(T__MVSEM t) {
			//stt_dbg_log("move semantics!\n");
			extendTailIfRequired();
			T* r = new (&(pageQueueImpl::pagePtr(tail)[tail->ph.localSize])) T(std::move(t));
			tail->ph.localSize++;
			head->ph.totalSize++;
			return r;
			}
		
		iterator iter_at(const uint32_t idx) {
			// returns an iterator at a specified index
			if (!head) return end();
			if (idx >= size()) return end();
			uint32_t idx2 = idx;
			P* w = head;
			while (w && w->ph.localSize < idx2) {
				idx2 -= w->ph.localSize;
				w = (P*) w->ph.next;
				}
			if (!w) return end();
			iterator it;
			it.init(w);
			it.ptr += idx2;
			return it;
			}
		
		iterator begin() {
			iterator it;
			it.init(head);
			return  it;
			}
			
		iterator end() {
			iterator it;
			it.init(NULL);
			return  it;
			}
		};
	
	}


