#define STT_STT_NOCOPY(X) \
private:								\
	X(const X& other);					\
	X& operator =(const X & other);		\
public:	

#hdr
namespace stt {
	template<typename T, typename P>
	struct pageQueueImpl;
	
	template <typename T>
	using pageQueue = pageQueueImpl<T,pageU>;
	}

#define STT_PAGEQUEUE_MVSEM pageQueueImpl&&
#define STT_PAGEQUEUEBUMPSTORAGE_MVSEM pageQueueBumpStorage&&
#end

#src
#end

namespace stt {	
	template<typename T, typename P>
	struct pageQueueImpl {
		// Purpose: a thin std::vector replacement with discontigious storage of fixed-size blocks
		P* head;
		P* tail;
		
		struct iterator {
			T* ptr;
			T* localEnd;
			P* currentPage;
			
			void init(P* page) {
				currentPage = page;
				if (currentPage) {
					ptr = pageQueueImpl::pagePtr(currentPage);
					localEnd = &ptr[currentPage->ph.localSize];
					}
				else {
					ptr = NULL;
					localEnd = NULL;
					}
				}
			
			inline void incr() {
				if (ptr) // do not increment a null pointer
					ptr++;
				while (ptr == localEnd && currentPage) // if we are at the end of a page then increment to the next non-empty page
					incr_nonInline();
				}
				
			void incr_nonInline() {
				currentPage = (P*) currentPage->ph.next;
				if (currentPage) {
					ptr = pageQueueImpl::pagePtr(currentPage);
					localEnd = &ptr[currentPage->ph.localSize];
					}
				else {
					ptr = NULL;
					localEnd = NULL;
					}
				}
				
			inline typename pageQueueImpl<T,P>::iterator& operator++() {
				incr();
				return *this;
				}
				
			inline bool operator!=(const iterator & other) const { return ptr != other.ptr; }
			inline T operator* () { return *ptr; }
			};
		
		//////////////////////////////////////////////////////////////////////////
		inline pageQueueImpl () : head(NULL), tail(NULL) {}
		~pageQueueImpl() { clear(); }
		
		// pageQueues cannot be copied, only moved
		// move assign and move construct are needed for std::swap auto implementation
		inline void move_impl(STT_PAGEQUEUE_MVSEM other) { head = other.head; tail = other.tail; other.head = NULL; other.tail = NULL; }
		inline pageQueueImpl(STT_PAGEQUEUE_MVSEM other) { move_impl(std::move(other)); }
		inline pageQueueImpl<T,P>& operator= (STT_PAGEQUEUE_MVSEM other) { clear(); move_impl(std::move(other)); return *this; }
		STT_STT_NOCOPY(pageQueueImpl)
		
		// Allocators/deallocators go here
		static P* allocPage () {
			P* p = ThreadSafePageAllocatorTemplates::allocGeneric<P>();
			p->initHeader();
			return p;
			}
		static P* allocPages (const uint32_t nPages) {
			if (nPages == 0) return NULL;
			P* store[nPages];
			ThreadSafePageAllocatorTemplates::allocGenericBatch<P>(&store[0], nPages);
			return pageHeader::buildList((pageHeader**) &store[0], nPages);
			}
		static void freePage(P* page) {
			ThreadSafePageAllocatorTemplates::freeGeneric<P>(page);
			}
		static void freePagesList(P* pageList) {
			ThreadSafePageAllocatorTemplates::freeGenericList<P>(pageList);
			}
			
		// psuedo-private methods
		void extendTailIfRequired() {
			if (!tail || tail->ph.localSize >= pageLocalCapacity())
				extendTail();
			}
		
		void extendTail () {
			if (!tail) {
				head = allocPage();
				tail = head;
				return;
				}
			if (!tail->ph.next)
				tail->ph.next = (pageHeader*) allocPage();
			tail = (P*) tail->ph.next;
			}
		
		P* trueTail() const {
			// returns the true end of the linked list
			P* t = tail;
			if (!t) return t;
			while (t->ph.next)
				t = (P*) t->ph.next;
			return t;
			}
		
		// capacity
		static STT_CONSTEXPR__size_t pageLocalCapacity()         { return P::capacity() / sizeof(T);  }
		static STT_CONSTEXPR__T* pagePtr(P* const p)             { return (T*) &p->_data[STT_PAGE_HEADER_SIZE]; }
		static const STT_CONSTEXPR__T* pagePtr(const P* const p) { return (const T*) &p->_data[STT_PAGE_HEADER_SIZE]; }
				
		inline uint32_t size() const { return head ? head->ph.totalSize : 0; }
		uint32_t numPages () const { return head ? head->ph.listLength() : 0; }
		
		
		// std::vector like stuff goes here:
		void clear() {
			if constexpr(std::is_trivially_destructible<T>::value) {
				// we don't need to invoke destructors so we can just throw away the linked list
				if (head) {
					head->ph.cachedWorkingEnd = (pageHeader*) trueTail();
					freePagesList(head);
					}
				}
			else {
				// we need to itterate through the linked list and destroy every object
				P* w = head;
				while (w) {
					P* t = w;
					w = (P*) w->ph.next;
					call_destructors_for_page(t);
					freePage(t);
					}
				}
			head = NULL;
			tail = NULL;
			}
			
		static void call_destructors_for_page(P* t) {
			T* arr = pagePtr(t);
			const uint32_t sz = t->ph.localSize;
			for (uint32_t i = 0; i < sz; ++i)
				arr[i].~T();
			}
			
		void clearKeepingFirstPage() {
			// Clears the pageQueue but keeps the first page
			if (head && head->next) {
				pageQueueImpl tmp;
				tmp.head = head->next;
				tmp.head->ph.cachedWorkingEnd = tail;
				tmp.tail = tail;
				tmp.clear();
				head->ph.next = NULL;
				tail = head; 
				if constexpr(!std::is_trivially_destructible<T>::value)
					call_destructors_for_page(head);
				head->ph.localSize = 0;
				head->ph.totalSize = 0;
				}
			}
		
		void swap(pageQueueImpl& other) {
			std::swap(head, other.head);
			std::swap(tail, other.tail);
			}
		
		void concatenate(STT_PAGEQUEUE_MVSEM other) {
			// transfers the other queue to the end of this
			if (!other.head)
				return;
			if (tail) {
				tail->ph.next = (pageHeader*) other.head;
				tail = other.tail;
				}
			else {
				head = other.head;
				tail = other.tail;
				}
			other.head = NULL;
			other.tail = NULL;
			}
		
		inline void reserve(const uint32_t sz) {
			// no-op
			// TBD - allocates pages and links them. Tail is set to the push_back write-head but trueTail() is the end of allocated storage
			if (sz <= size()) return;
			if (tail)
				if (tail->ph.next)
					return; // pages are already preallocated
			
			//                   needed          avaliable in tail page
			const int32_t want = (sz - size()) - (pageLocalCapacity() - tail->ph.localSize);
			if (want <= 0) return; // already capacity avaliable
			uint32_t nPagesToAllocate = want/pageLocalCapacity();
			tail->ph.next = allocPages(nPagesToAllocate);
			}
		
		inline void push_back(const T& t) {
			extendTailIfRequired();
			new (&(pageQueueImpl::pagePtr(tail)[tail->ph.localSize])) T(t);
			tail->ph.localSize++;
			head->ph.totalSize++;
			}
		
		inline void push_back(T__MVSEM t) {
			//stt_dbg_log("move semantics!\n");
			extendTailIfRequired();
			new (&(pageQueueImpl::pagePtr(tail)[tail->ph.localSize])) T(std::move(t));
			tail->ph.localSize++;
			head->ph.totalSize++;
			}
		
		iterator iter_at(const uint32_t idx) {
			// returns an iterator at a specified index
			if (!head) return end();
			if (idx >= size()) return end();
			uint32_t idx2 = idx;
			P* w = head;
			while (w && w->ph.localSize < idx2) {
				idx2 -= w->ph.localSize;
				w = (P*) w->ph.next;
				}
			if (!w) return end();
			iterator it;
			it.init(w);
			it.ptr += idx2;
			return it;
			}
		
		iterator begin() {
			iterator it;
			it.init(head);
			return  it;
			}
			
		iterator end() {
			iterator it;
			it.init(NULL);
			return  it;
			}
		};
	
	
	template<typename P>
	struct pageQueueBumpStorage {
		// Purpose: storage for interned strings (or arbitary pod). Each string must be smaller than a page in size
		// This is one-way storage - each push_back returns a string_view and each store cannot be resized or moved.
		// You must track these string_views yourself
		// You cannot erase, just purge the entire list with (clear())
		// empty strings are not stored, an empty string_view is returned if you push_back
		pageQueueImpl<char,P> store;
		typedef uint16_t writeSizeType; // writeSizeType(-1) is the maximum element size
		
		pageQueueBumpStorage() {}
		~pageQueueBumpStorage() {}
		
		// pageQueues cannot be copied, only moved
		// move assign and move construct are needed for std::swap auto implementation
		inline pageQueueBumpStorage(STT_PAGEQUEUEBUMPSTORAGE_MVSEM other) { store.move_impl(std::move(store.other)); }
		inline pageQueueBumpStorage<P>& operator= (STT_PAGEQUEUEBUMPSTORAGE_MVSEM other) { clear(); store.move_impl(std::move(store.other)); return *this; }
		STT_STT_NOCOPY(pageQueueBumpStorage)
		
		
		inline stt::string_view push_back(const stt::string_view& sv) {
			return push_back_compact(sv.data(), sv.size());
			}
		stt::string_view push_back(const char* str, const uint32_t size) {
			// Fast - tacks on the string at the end
			if (!size) return stt::string_view(NULL, 0);
			const uint32_t wantsSize = size + sizeof(writeSizeType);
			if (wantsSize > writeSizeType(-1))
				stt::error::array_out_of_bounds(size, writeSizeType(-1));
			if (wantsSize > store.pageLocalCapacity())
				stt::error::array_out_of_bounds(wantsSize, store.pageLocalCapacity());
			
			store.extendTailIfRequired();
			if (remainingBytesIn(store.tail) < wantsSize)
				store.extendTail();
			return writeBufferRaw(store.tail, str, size);
			}
			
		struct pushBackLookupHint { 
			P* page;
			uint32_t avaliableSize;
			inline pushBackLookupHint() : page(NULL), avaliableSize(0) {}
			};
		
		inline stt::string_view push_back_compact(const stt::string_view& sv, pushBackLookupHint* hint = NULL) {
			return push_back_compact(sv.data(), sv.size());
			}
		stt::string_view push_back_compact(const char* str, const uint32_t size, pushBackLookupHint* hint = NULL) {
			// Slow - itterates through list to find first page that'll fit this string and puts there
			// usage: 1. `push_back_compact(str, size);` or
			//        2. `pushBackLookupHint hint; for (each_string) { push_back_compact(str, size, &hint); }`
			// if hint is non-null then start searching from (*hint). This optimises for the case in a loop where a
			// big alloc causes a large gap in the middle of the list that can be filled with small 
			if (!size) return stt::string_view(NULL, 0);
			const uint32_t wantsSize = size + sizeof(writeSizeType);
			if (wantsSize > store.pageLocalCapacity())
				stt::error::array_out_of_bounds(wantsSize, store.pageLocalCapacity());
			
			P* page = hint ? hint->page : store.head;
			
			while (page) {
				uint32_t remainingBytes = remainingBytesIn(page);
				if (hint) {
					// update biggest free-space page if avaliable
					if (remainingBytes > hint->avaliableSize) {
						hint->page = page;
						hint->avaliableSize = remainingBytes;
						}
					}
				if (remainingBytes >= wantsSize) {
					if (hint->page == page)
						hint->avaliableSize -= wantsSize;
					return writeBufferRaw(page, str, size);
					}
				page = (P*) page->ph.next;
				}
			if (hint) {
				hint->page = NULL; // nothing fit so lookup again next insert
				hint->avaliableSize = 0;
				}
			// fallback to tail push_back
			return push_back(str, size);
			}
		
		inline void swap(pageQueueBumpStorage& other) { store.swap(other); }
		inline void clear() { store.clear(); }
		inline void clearKeepingFirstPage() { store.clearKeepingFirstPage(); }
		
		inline uint32_t remainingBytesIn(P* t) const { return store.pageLocalCapacity() - t->ph.localSize; }
			
		stt::string_view writeBufferRaw(P* page, const char * str, const writeSizeType size) {
			char* ptr = store.pagePtr(page);
			*((writeSizeType*) ptr) = size;
			ptr += sizeof(writeSizeType);
			stt_memcpy((uint8_t*) ptr, (const uint8_t*) str, size);
			
			page->ph.localSize += size + sizeof(writeSizeType);
			
			return stt::string_view(ptr, size);
			}
		};
	}


