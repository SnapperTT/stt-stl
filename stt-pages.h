// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// mt_page_allocator_impl.hh
//

#ifndef LZZ_mt_page_allocator_impl_hh
#define LZZ_mt_page_allocator_impl_hh

#ifndef STT_TLS_WRAPPER
	#ifdef __WIN32
		#define STT_TLS_WRAPPER WindowsThreadLocalWrapper
		#define STT_WINDOWS_TLS 1
		#define STT_thread_local_PATL_Data int
		#define STT_DWORD DWORD
	#else
		#define STT_TLS_WRAPPER NativeThreadLocalWrapper
	#endif
#endif
#ifndef STT_thread_local_PATL_Data
	#define STT_thread_local_PATL_Data thread_local PATL_Data
#endif
#ifndef STT_DWORD
	#define STT_DWORD int
#endif

#if defined(STT_PASSTHROUGH_TL_PAGE_ALLOCATOR)
	#define STT_PASSTHROUGH_TL_PAGE_ALLOCATOR_IMPL 1
#elif defined(STT_PASSTHROUGH_TL_PAGE_ALLOCATOR_BACKEND)
	#define STT_PASSTHROUGH_TL_PAGE_ALLOCATOR_IMPL 1
#endif

namespace stt {
	struct PATL_Data;
	int dbg_getNPagesAllocated_forward();
	}
	
#include <mutex>
#include <atomic>
#if STT_STL_DEBUG_PAGE
	#include <thread>
#endif
#define LZZ_INLINE inline
namespace stt
{
  struct PATL_Data;
}
namespace stt
{
  struct NativeThreadLocalWrapper
  {
    static STT_thread_local_PATL_Data * mData;
    PATL_Data * getTlsData ();
    void setTlsData (PATL_Data * ptr);
  };
}
namespace stt
{
  struct WindowsThreadLocalWrapper
  {
    STT_DWORD dwTlsIndex;
    WindowsThreadLocalWrapper ();
    ~ WindowsThreadLocalWrapper ();
    PATL_Data * getTlsData ();
    void setTlsData (PATL_Data * ptr);
  };
}
namespace stt
{
  class BackendPagePool;
}
namespace stt
{
  class ThreadLocalPagePool;
}
namespace stt
{
  class BackendPagePool
  {
  public:
    pageTypeEnum mPageType;
    uint32_t batchSize;
    pageHeader * allocFreeList;
    std::mutex mMutex;
    std::atomic <pageHeader*> _list;
    BackendPagePool ();
    ~ BackendPagePool ();
    void init (pageTypeEnum const _pageType, uint32_t const _batchSize);
    void dbg_print_status ();
    uint32_t freeAllToSystem ();
    void freePages (pageHeader * * pages, uint32_t const nPages);
    void atomicMerge (pageHeader * _insert, uint32_t const _nReturned);
    void atomicMerge (pageHeader * _insert);
    pageHeader * atomicTake ();
    void bulkFetch (pageHeader * * store, uint32_t const nPages);
  };
}
namespace stt
{
  class PassthroughPageAllocator
  {
  public:
    static void allocGeneric (pageTypeEnum const pageType, pageHeader * * pages, uint32_t const nPages);
    template <typename T>
    static void allocGeneric (pageHeader * * pages, uint32_t const nPages);
    template <typename T>
    static void freeGeneric (pageHeader * * pages, uint32_t const nPages);
    template <typename T>
    static void freeGenericList (pageHeader * pagesLinkedList);
  };
}
namespace stt
{
  class ThreadLocalPagePool
  {
  public:
    pageHeader * freelist;
    pageTypeEnum mPageType;
    int nPagesInFreeList;
    int requestAmount;
    int maxFreeListAmount;
    int threadId;
    char (snstt_dbg_logBuffer) [64];
    static std::atomic <int> staticNextId;
    static int const DEFAULT_THREADLOCAL_MIN_FREELIST_PAGES = 10;
    static int const DEFAULT_THREADLOCAL_MAX_FREELIST_PAGES = 20;
    ThreadLocalPagePool ();
    void init (pageTypeEnum const _pageType, uint32_t const _threadId);
    ~ ThreadLocalPagePool ();
    void setMinMaxFreelistPages (uint32_t const requestSize, uint32_t const maxCachedSize);
    void getMinMaxFreelistPages (uint32_t & requestSizeOut, uint32_t & maxCachedOut);
    void returnAllPages ();
    char const * getThreadLabel ();
    void dbg_print_status ();
    void dbg_dump_freelist ();
    void dbgMarkPageAllocated (pageHeader * page);
    void dbgMarkPageFreed (pageHeader * page);
    void dbgMarkPageFreedList (pageHeader * pagesLinkedList);
    void allocPages (pageHeader * * pages, uint32_t const nPages);
    void freePages (pageHeader * * pages, uint32_t const nPages);
    void freePagesList (pageHeader * pagesLinkedList, uint32_t const knownCount = 0);
    void returnPagesToGlobalPool (pageHeader * returnList, uint32_t const nReturned);
  };
}
namespace stt
{
  struct PATL_Data
  {
    ThreadLocalPagePool pageAlloc;
    ThreadLocalPagePool jumboPageAlloc;
    PATL_Data ();
    ~ PATL_Data ();
  };
}
namespace stt
{
  class ThreadSafePageAllocatorImpl
  {
  public:
    STT_TLS_WRAPPER mTls;
    BackendPagePool PageGlobalFreeList;
    BackendPagePool JumboGlobalFreeList;
    static std::atomic <int> dbg_totalPagesAllocated;
    ThreadSafePageAllocatorImpl ();
    ~ ThreadSafePageAllocatorImpl ();
    static uint8_t * raw_alloc (uint64_t const sz);
    static void raw_free (uint8_t * ptr, uint64_t const sz);
    static ThreadSafePageAllocatorImpl & get ();
    void perf_warning (char const * msg);
    void initThreadLocalPools ();
    void cleanupThreadLocalPools ();
    uint32_t cleanupBackendPools ();
    PATL_Data * getThreadLocalPools ();
    void allocPages (pageU * * pages, uint32_t const nPages);
    void freePages (pageU * * pages, uint32_t const nPages);
    void freePagesList (pageU * pageList);
    void allocJumboPages (jumboPageU * * pages, uint32_t const nPages);
    void freeJumboPages (jumboPageU * * pages, uint32_t const nPages);
    void freeJumboPagesList (jumboPageU * pageList);
    static void systemAllocate (pageTypeEnum const mPageType, uint32_t const nPagesTotal, uint32_t const nSplit, pageHeader * * groupA, pageHeader * * groupB);
    static void systemAllocate_impl (uint32_t const sizeofPageType, uint32_t const nPagesTotal, uint32_t const nSplit, pageHeader * * groupA, pageHeader * * groupB);
    static uint32_t systemFreeList (pageHeader * head);
  };
}
namespace stt
{
  LZZ_INLINE PATL_Data * NativeThreadLocalWrapper::getTlsData ()
                                       { return mData; }
}
namespace stt
{
  LZZ_INLINE void NativeThreadLocalWrapper::setTlsData (PATL_Data * ptr)
                                               { mData = ptr; }
}
namespace stt
{
  LZZ_INLINE PATL_Data * WindowsThreadLocalWrapper::getTlsData ()
                                       {
		#ifdef STT_WINDOWS_TLS
		return (PATL_Data*) TlsGetValue(dwTlsIndex);
		#else
		return NULL;
		#endif
		}
}
namespace stt
{
  LZZ_INLINE void WindowsThreadLocalWrapper::setTlsData (PATL_Data * ptr)
                                               {
		#ifdef STT_WINDOWS_TLS
		TlsSetValue(dwTlsIndex, ptr);
		#endif
		}
}
namespace stt
{
  LZZ_INLINE void BackendPagePool::atomicMerge (pageHeader * _insert, uint32_t const _nReturned)
                                                                                {
		#if STT_STL_DEBUG_PAGE
		stt_dbg_log("BackendPagePool atomicMerge: %p %i\n", _insert, _nReturned);
		#endif
		atomicMerge(_insert);
		}
}
namespace stt
{
  template <typename T>
  void PassthroughPageAllocator::allocGeneric (pageHeader * * pages, uint32_t const nPages)
                                                                            {
		#ifdef STT_PASSTHROUGH_TL_PAGE_ALLOCATOR_IMPL
			#if STT_STL_TRACK_SYSTEM_ALLOCATIONS
				ThreadSafePageAllocatorImpl::dbg_totalPagesAllocated += nPages;
			#endif
			for (uint32_t i = 0; i < nPages; ++i)
				pages[i] = (pageHeader*) new T;
		#endif
		}
}
namespace stt
{
  template <typename T>
  void PassthroughPageAllocator::freeGeneric (pageHeader * * pages, uint32_t const nPages)
                                                                           {
		#ifdef STT_PASSTHROUGH_TL_PAGE_ALLOCATOR_IMPL
			#if STT_STL_TRACK_SYSTEM_ALLOCATIONS
				ThreadSafePageAllocatorImpl::dbg_totalPagesAllocated -= nPages;
			#endif
			for (uint32_t i = 0; i < nPages; ++i)
				delete ((T*) pages[i]);
		#endif
		}
}
namespace stt
{
  template <typename T>
  void PassthroughPageAllocator::freeGenericList (pageHeader * pagesLinkedList)
                                                                 {
		#ifdef STT_PASSTHROUGH_TL_PAGE_ALLOCATOR_IMPL
			pageHeader* tmp = pagesLinkedList;
			#if STT_STL_TRACK_SYSTEM_ALLOCATIONS
			int cnt = 0;
			#endif
			while (tmp) {
				pageHeader* d = tmp;
				tmp = tmp->next;
				delete ((T*) d);
				#if STT_STL_TRACK_SYSTEM_ALLOCATIONS
					cnt++;
				#endif
				}
			#if STT_STL_TRACK_SYSTEM_ALLOCATIONS
				ThreadSafePageAllocatorImpl::dbg_totalPagesAllocated -= cnt;
			#endif
		#endif
		}
}
namespace stt
{
  LZZ_INLINE void ThreadLocalPagePool::dbgMarkPageAllocated (pageHeader * page)
                                                           {
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("ThreadLocalPagePool %s: Allocating page %p\n", getThreadLabel(), page);
		#endif
		}
}
namespace stt
{
  LZZ_INLINE void ThreadLocalPagePool::dbgMarkPageFreed (pageHeader * page)
                                                       {
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("ThreadLocalPagePool %s: Freeing page %p\n", getThreadLabel(), page);
		#endif
		}
}
namespace stt
{
  LZZ_INLINE void ThreadLocalPagePool::dbgMarkPageFreedList (pageHeader * pagesLinkedList)
                                                                      {
		#if STT_STL_DEBUG_PAGE
			pageHeader* tmp = pagesLinkedList;
			while (tmp) {
				dbgMarkPageFreed(tmp);
				tmp = tmp->next;
				}
		#endif
		}
}
namespace stt
{
  LZZ_INLINE void ThreadSafePageAllocatorImpl::perf_warning (char const * msg)
                                                   {
		stt_dbg_log("stt::ThreadSafePageAllocator WARNING: %s\n", msg);
		}
}
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_mt_page_allocator_impl
#define STT_STL_IMPL_DOUBLE_GUARD_mt_page_allocator_impl
#define LZZ_OVERRIDE
// mt_page_allocator_impl.cpp
//

#define LZZ_INLINE inline
namespace stt
{
  STT_thread_local_PATL_Data * NativeThreadLocalWrapper::mData;
}
namespace stt
{
  WindowsThreadLocalWrapper::WindowsThreadLocalWrapper ()
                                    {
		dwTlsIndex = 0;
		#ifdef STT_WINDOWS_TLS
		dwTlsIndex = TlsAlloc();
		if (dwTlsIndex == TLS_OUT_OF_INDEXES)
			STT_STL_ABORT();
		#endif
		}
}
namespace stt
{
  WindowsThreadLocalWrapper::~ WindowsThreadLocalWrapper ()
                                     {
		#ifdef STT_WINDOWS_TLS
		TlsFree(dwTlsIndex);
		#endif
		}
}
namespace stt
{
  BackendPagePool::BackendPagePool ()
                          {
		mPageType = pageTypeEnum::PAGE_TYPE_UNSET;
		batchSize = 1; // really set in ThreadSafeAllocatorImpl()
		
		allocFreeList = NULL;
		_list = NULL;
		}
}
namespace stt
{
  BackendPagePool::~ BackendPagePool ()
                           {
		#if STT_STL_DEBUG_PAGE
		stt_dbg_log("~BackendPagePool %s\n", pageTypeEnumToString(mPageType));
		dbg_print_status();
		#endif
		freeAllToSystem();
		}
}
namespace stt
{
  void BackendPagePool::init (pageTypeEnum const _pageType, uint32_t const _batchSize)
                                                                            {
		mPageType = _pageType;
		batchSize = _batchSize;
		}
}
namespace stt
{
  void BackendPagePool::dbg_print_status ()
                                {
		mMutex.lock();
		pageHeader* h = atomicTake();
		stt_dbg_log("\tBackendPagePool (%s): %p, %i -- %p, %i\n", pageTypeEnumToString(mPageType), allocFreeList, allocFreeList ? allocFreeList->listLength() : 0, h, h ? h->listLength() : 0);
		if (h) atomicMerge(h);
		mMutex.unlock();
		}
}
namespace stt
{
  uint32_t BackendPagePool::freeAllToSystem ()
                                   {
		// Takes all pages held here and deallocates them
		// returns number of pages deallocated if STT_STL_TRACK_SYSTEM_ALLOCATIONS is defined, else returns 0
		mMutex.lock();
		pageHeader* h = atomicTake();
		#if STT_STL_DEBUG_PAGE
		stt_dbg_log("BackendPagePool freeAll IN: h: %p, allocFreeList: %p\n", h, allocFreeList);
		#endif
		if (h) {
			if (allocFreeList)
				allocFreeList->appendList(h);
			else
				allocFreeList = h;
			}
		#if STT_STL_DEBUG_PAGE
		stt_dbg_log("BackendPagePool freeAll: allocFreeList %p\n", allocFreeList);
		#endif
		uint32_t r = ThreadSafePageAllocatorImpl::systemFreeList(allocFreeList);
		allocFreeList = NULL;
		mMutex.unlock();
		return r;
		}
}
namespace stt
{
  void BackendPagePool::freePages (pageHeader * * pages, uint32_t const nPages)
                                                                  {
		// For the situation where we have an array of pages
		if (!nPages) return;
		atomicMerge(pageHeader::buildList(pages, nPages), nPages);
		}
}
namespace stt
{
  void BackendPagePool::atomicMerge (pageHeader * _insert)
                                              {
		// Adds @_insert to the atomic free list @this->_list
		#ifdef STT_PASSTHROUGH_TL_PAGE_ALLOCATOR_BACKEND
			if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
				PassthroughPageAllocator::freeGenericList<pageU>(_insert);
			else if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
				PassthroughPageAllocator::freeGenericList<jumboPageU>(_insert);
			else
				STT_STL_ABORT();
			return;
		#endif
		// Remove head from atomic to working memory
		pageHeader* workingList = atomicTake();
		// _list is now NULL
		
		#if STT_STL_DEBUG_PAGE
			int wll = workingList ? workingList->listLength() : 0;
			int ill = _insert ? _insert->listLength() : 0;
		#endif
		
		// merge the lists
		if (workingList)
			_insert->appendList(workingList);
		workingList = _insert;
		
		#if STT_STL_DEBUG_PAGE
			int wll2 = workingList ? workingList->listLength() : 0;
			stt_dbg_log("BackendPagePool atomicMerge impl, list lengths: %i + %i => %i\n", wll, ill, wll2);
			//abort();
		#endif
		
		// replace NULL head with the working list
		pageHeader* nullList = NULL;
		if (!_list.compare_exchange_strong(nullList, workingList)) {
			// failed merge, this must have been due to pre-emption, re-merge
			atomicMerge(workingList);
			}
		}
}
namespace stt
{
  pageHeader * BackendPagePool::atomicTake ()
                                  {
		// Reads the value of @_list and replaces it with NULL
		pageHeader* workingList = _list.load();
		while (!_list.compare_exchange_weak(workingList, NULL, std::memory_order_release, std::memory_order_relaxed));
		return workingList; 
		}
}
namespace stt
{
  void BackendPagePool::bulkFetch (pageHeader * * store, uint32_t const nPages)
                                                                  {
		// Yank off atomic list and merge the linked lists
		if (!nPages) return;
		#ifdef STT_PASSTHROUGH_TL_PAGE_ALLOCATOR_BACKEND
			if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
				PassthroughPageAllocator::allocGeneric<pageU>(store, nPages);
			else if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
				PassthroughPageAllocator::allocGeneric<jumboPageU>(store, nPages);
			else
				STT_STL_ABORT();
			for (uint32_t i = 1; i < nPages; ++i) {
				store[i-1]->next = store[i];
				}
			store[nPages-1]->next = NULL;
			store[0]->cachedWorkingEnd = store[nPages-1];
			return;
		#endif
		
		pageHeader* h = atomicTake();
		mMutex.lock();
		
		#if STT_STL_DEBUG_PAGE
		{
			const int l1 = allocFreeList ? allocFreeList->listLength() : 0;
			const int l2 = h ? h->listLength() : 0;
			stt_dbg_log ("BackendPagePool: bulkFetch in, request: %i,  allocFreeList len: %i, allocFreeList len: %i, total free: %i, total system allocated: %i\n", nPages, l1, l2, l1 + l2, stt::dbg_getNPagesAllocated_forward());
		}
		#endif
			
		if (h) {
			if (allocFreeList)
				allocFreeList->appendList(h);
			else
				allocFreeList = h;
			}
		
		pageHeader* w = allocFreeList;
		uint32_t i = 0;
		if (w) {
			for (i = 0; i < nPages && w; ++i) {//->next; ++i) {
				store[i] = w;
				w = w->next;
				}
			}
			
		const uint32_t nAllocated = i;
		if (i == nPages) {
			// cut the linked list here
			pageHeader* newHead = w;//->next;
			store[nPages-1]->next = NULL;
			store[nPages-1]->cachedWorkingEnd = NULL;
			if (newHead)
				newHead->cachedWorkingEnd = allocFreeList->cachedWorkingEnd;
			allocFreeList = newHead;
			mMutex.unlock();
			
			store[nPages-1]->next = NULL;
			
			
			#if STT_STL_DEBUG_PAGE
				stt_dbg_log ("BackendPagePool: bulkFetch out path a, %i pages allocated\n", i);
			#endif
			return;
			}
		
		//batchSize = 0;
		
		// we have a parital linked list, we need system allocation
		pageHeader* remaining = NULL;
		pageHeader* leftovers = NULL;
		const uint32_t nPagesToSystemAllocate = (batchSize + nPages - nAllocated);
		const uint32_t nSplit =  nPages - nAllocated;
		ThreadSafePageAllocatorImpl::systemAllocate(mPageType, nPagesToSystemAllocate, nSplit, &remaining, &leftovers);
		
		if (i)
			store[i-1]->next = remaining;
		for (; i < nPages; ++i) {
			#if STT_STL_DEBUG_PAGE
				STT_STL_ASSERT(remaining, "remaining is not valid");
			#endif
			store[i] = remaining;
			remaining = remaining->next;
			}
		store[nPages-1]->next = NULL;
		
		// the entire free list has been consumed so we can dispose of it here
		//allocFreeList = leftovers;
		
		#if STT_STL_DEBUG_PAGE
		stt_dbg_log ("BackendPagePool: bulkFetch out path b %s, total: %i, groupA: %i, groupB: %i\n", pageTypeEnumToString(mPageType), nPagesToSystemAllocate, nSplit, nPagesToSystemAllocate - nSplit);
		int cnt = 0;
		pageHeader* tail = leftovers->endCountingDumping(cnt);
		stt_dbg_log ("BackendPagePool: allocFreeList: %p, next: %p, end: %p, true end: %p, length: %i\n", leftovers, leftovers->next, leftovers->cachedWorkingEnd, tail, cnt);
		STT_STL_ASSERT(leftovers->cachedWorkingEnd == tail, "BackendPagePool freelist is corrupt");
		#endif
		
		allocFreeList = leftovers;
		mMutex.unlock();
		}
}
namespace stt
{
  void PassthroughPageAllocator::allocGeneric (pageTypeEnum const pageType, pageHeader * * pages, uint32_t const nPages)
                                                                                                         {
		#ifdef STT_PASSTHROUGH_TL_PAGE_ALLOCATOR_IMPL
		if (pageType == pageTypeEnum::PAGE_TYPE_NORMAL) 
			return allocGeneric<pageU>(pages, nPages);
		else if (pageType == pageTypeEnum::PAGE_TYPE_JUMBO) 
			return allocGeneric<jumboPageU>(pages, nPages);
		else
			STT_STL_ABORT();
		#endif
		}
}
namespace stt
{
  std::atomic <int> ThreadLocalPagePool::staticNextId = 0;
}
namespace stt
{
  int const ThreadLocalPagePool::DEFAULT_THREADLOCAL_MIN_FREELIST_PAGES;
}
namespace stt
{
  int const ThreadLocalPagePool::DEFAULT_THREADLOCAL_MAX_FREELIST_PAGES;
}
namespace stt
{
  ThreadLocalPagePool::ThreadLocalPagePool ()
                              {}
}
namespace stt
{
  void ThreadLocalPagePool::init (pageTypeEnum const _pageType, uint32_t const _threadId)
                                                                           {
		mPageType = _pageType;
		freelist = NULL;
		nPagesInFreeList = 0;
		
		setMinMaxFreelistPages(DEFAULT_THREADLOCAL_MIN_FREELIST_PAGES, DEFAULT_THREADLOCAL_MAX_FREELIST_PAGES);
		
		threadId = _threadId;
		stt_memset((uint8_t*) &snstt_dbg_logBuffer[0], 0, 64);
		
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("INIT NEW ThreadLocalPagePool %s\n", getThreadLabel());
		#endif
		}
}
namespace stt
{
  ThreadLocalPagePool::~ ThreadLocalPagePool ()
                               {
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("~ThreadLocalPagePool %s, nPagesInFreeList: %i\n", getThreadLabel(), nPagesInFreeList);
			dbg_print_status();
		#endif
		returnAllPages();
		}
}
namespace stt
{
  void ThreadLocalPagePool::setMinMaxFreelistPages (uint32_t const requestSize, uint32_t const maxCachedSize)
                                                                                              {
		requestAmount = requestSize;
		maxFreeListAmount = maxCachedSize;
		STT_STL_ASSERT(maxFreeListAmount >= requestAmount*2, "freelist size must be at least twice as big as the request size");
		}
}
namespace stt
{
  void ThreadLocalPagePool::getMinMaxFreelistPages (uint32_t & requestSizeOut, uint32_t & maxCachedOut)
                                                                                        {
		requestSizeOut = requestAmount;
		maxCachedOut = maxFreeListAmount;
		}
}
namespace stt
{
  void ThreadLocalPagePool::returnAllPages ()
                              {
		returnPagesToGlobalPool(freelist, nPagesInFreeList);
		freelist = NULL;
		}
}
namespace stt
{
  char const * ThreadLocalPagePool::getThreadLabel ()
                                      {
		#if STT_STL_DEBUG_PAGE_THREAD_LABEL
			return STT_STL_DEBUG_PAGE_THREAD_LABEL(this);
		#else
			#if STT_STL_DEBUG_PAGE
				snprintf(snstt_dbg_logBuffer, 64, "[T%i %x %p]", threadId, (unsigned int) std::hash<std::thread::id>()(std::this_thread::get_id()), this);
				return snstt_dbg_logBuffer;
			#endif
		#endif
		return NULL;
		}
}
namespace stt
{
  void ThreadLocalPagePool::dbg_print_status ()
                                {
		#if STT_STL_DEBUG_PAGE
			int fll = freelist ? freelist->listLength() : 0;
			stt_dbg_log("\tThreadLocalPagePool (%s, %s): %p -> %p, %i/%i\n", pageTypeEnumToString(mPageType), getThreadLabel(), freelist, freelist ? freelist->cachedWorkingEnd : NULL, fll, nPagesInFreeList);
			if (fll != nPagesInFreeList)
				dbg_dump_freelist();
			STT_STL_ASSERT (fll == nPagesInFreeList, "freelist is corrupt (1)");
		#endif
		}
}
namespace stt
{
  void ThreadLocalPagePool::dbg_dump_freelist ()
                                 {
		#if STT_STL_DEBUG_PAGE
			int i = 0;
			pageHeader* tmp = freelist;
			while (tmp) {
				stt_dbg_log("\tThreadLocalPagePool %s: Freelist %i: %p\n", getThreadLabel(), i, tmp);
				tmp = tmp->next;
				i++;
				}
			stt_dbg_log("\tThreadLocalPagePool %s: nPagesInFreeList %i, count: %i\n", getThreadLabel(), nPagesInFreeList, i);
			STT_STL_ASSERT (i == nPagesInFreeList, "freelist is corrupt (2)");
		#endif
		}
}
namespace stt
{
  void ThreadLocalPagePool::allocPages (pageHeader * * pages, uint32_t const nPages)
                                                                   {
		#ifdef STT_PASSTHROUGH_TL_PAGE_ALLOCATOR
			return PassthroughPageAllocator::allocGeneric(mPageType, pages, nPages);
		#endif
		#if STT_STL_DEBUG_PAGE
			const int listLength = freelist ? freelist->listLength() : 0;
			stt_dbg_log("ThreadLocalPagePool %s allocPages: nPages: %i, freelist length: %i, nPagesInFreeList %i -> %i \n", getThreadLabel(), nPages, listLength, nPagesInFreeList, nPagesInFreeList - nPages);
			STT_STL_ASSERT (listLength == nPagesInFreeList, "freelist is corrupt (3)");
		#endif
			
		uint32_t count = 0;
		if (freelist) {
			pageHeader* workingEnd = freelist->cachedWorkingEnd;
			while (freelist && count < nPages) {
				pages[count] = freelist;
				dbgMarkPageAllocated(pages[count]);
				count++;
				freelist = freelist->next;
				}
			if (freelist)
				freelist->cachedWorkingEnd = workingEnd;
			}
		if (count == nPages) {
			nPagesInFreeList -= count;
			return;
			}
		if (count < nPages) {
			// we are out of pages, request pages from TSPA (locking)
			const uint32_t countInit = count;
			const uint32_t want = requestAmount + nPages - count;	// Batch size + (num needed for this request)
			pageHeader* localStore[want];
			
			#if STT_STL_DEBUG_PAGE
				stt_dbg_log("ThreadLocalPagePool %s fetching from backend want: %i, nPages: %i, count: %i, (nPages - countInit): %i, requestAmount: %i\n", getThreadLabel(), want, nPages, count, (nPages-countInit), requestAmount);
			#endif
			
			if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
				ThreadSafePageAllocatorImpl::get().PageGlobalFreeList.bulkFetch(&localStore[0], want);
			else if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
				ThreadSafePageAllocatorImpl::get().JumboGlobalFreeList.bulkFetch(&localStore[0], want);
			else
				STT_STL_ABORT();
			
			#if STT_STL_DEBUG_PAGE
			{
			stt_dbg_log("ThreadLocalPagePool %s S0 localStore:\n", getThreadLabel());
			
			bool isBroken = false;
			for (uint32_t i = 0; i < want; ++i) {
				//if (i < want -1) localStore[i]->next = localStore[i+1];
				stt_dbg_log("\t%i: %p (-> %p), end: %p", i, localStore[i], localStore[i] ? localStore[i]->next : NULL, localStore[i] ? localStore[i]->cachedWorkingEnd : NULL);
				if (localStore[i]->next && i < want && localStore[i]->next != localStore[i+1]) {
					stt_dbg_log("!!! linked list is corrupt (localStore[%i] does not point to localStore[%i])", i, i+1);
					isBroken = true;
					}
				}
			if (isBroken)
				STT_STL_ABORT();
			stt_dbg_log("\n");
			}
			#endif
			
			uint32_t idx = 0;
			for (;count < nPages; ++count) {
				pages[count] = localStore[idx];
				dbgMarkPageAllocated(pages[count]);
				++idx;
				}
					
			#if STT_STL_DEBUG_PAGE
			stt_dbg_log("ThreadLocalPagePool %s S1 allocPages:\n", getThreadLabel());
				STT_STL_ASSERT(freelist == NULL, "freelist is null");
			#endif
			freelist = localStore[nPages - countInit];
			freelist->cachedWorkingEnd = localStore[want-1];
			nPagesInFreeList = requestAmount;
			
			#if STT_STL_DEBUG_PAGE
			stt_dbg_log("ThreadLocalPagePool %s S2 allocPages:\n", getThreadLabel());
				dbg_print_status();
			#endif
			}
		}
}
namespace stt
{
  void ThreadLocalPagePool::freePages (pageHeader * * pages, uint32_t const nPages)
                                                                  {
		// assembles pages into a linked list, then adds to the freelist
		if (!nPages) return;
		#ifdef STT_PASSTHROUGH_TL_PAGE_ALLOCATOR
		if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
			return PassthroughPageAllocator::freeGeneric<jumboPageU>(pages, nPages);
		else if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
			return PassthroughPageAllocator::freeGeneric<pageU>(pages, nPages);	
		else
			STT_STL_ABORT();
		#endif
		freePagesList(pageHeader::buildList(pages, nPages), nPages);
		}
}
namespace stt
{
  void ThreadLocalPagePool::freePagesList (pageHeader * pagesLinkedList, uint32_t const knownCount)
                                                                                       {
		// frees an already prepared linked list of pages
		// if the number of pages is not known then knownCount 
		#ifdef STT_PASSTHROUGH_TL_PAGE_ALLOCATOR
		if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
			return PassthroughPageAllocator::freeGenericList<jumboPageU>(pagesLinkedList);
		else if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
			return PassthroughPageAllocator::freeGenericList<pageU>(pagesLinkedList);
		else
			STT_STL_ABORT();
		#endif
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("ThreadLocalPagePool %s freePagesList IN:\n", getThreadLabel());
			dbg_dump_freelist();
		#endif
		
		uint32_t realKnownCount = knownCount;
		if (!realKnownCount) {
			pageHeader* tmp = pagesLinkedList;
			while (tmp) {
				tmp = tmp->next;
				realKnownCount++;
				}
			}
		dbgMarkPageFreedList(pagesLinkedList);
			
		nPagesInFreeList += realKnownCount;	
		
		if (freelist)
			pagesLinkedList->appendList(freelist);
		freelist = pagesLinkedList;
		
		if (nPagesInFreeList > maxFreeListAmount) {
			pageHeader* returnList = freelist->splitList(requestAmount);
			const uint32_t nReturned = nPagesInFreeList - requestAmount;
			returnPagesToGlobalPool(returnList, nReturned);			
			}
			
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("ThreadLocalPagePool %s freePagesList OUT:\n", getThreadLabel());
			dbg_dump_freelist();
		#endif
		}
}
namespace stt
{
  void ThreadLocalPagePool::returnPagesToGlobalPool (pageHeader * returnList, uint32_t const nReturned)
                                                                                       {
		if (!returnList) return;
		nPagesInFreeList -= nReturned;
		// Return pages to main cache
		if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
			ThreadSafePageAllocatorImpl::get().PageGlobalFreeList.atomicMerge(returnList, nReturned);
		else if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
			ThreadSafePageAllocatorImpl::get().JumboGlobalFreeList.atomicMerge(returnList, nReturned);
		else
			STT_STL_ABORT();
		}
}
namespace stt
{
  PATL_Data::PATL_Data ()
                    {
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("CONSTRUCT NEW PATL_Data %p\n", this);
		#endif
		int threadId = ThreadLocalPagePool::staticNextId++;
		pageAlloc.init(pageTypeEnum::PAGE_TYPE_NORMAL, threadId);
		jumboPageAlloc.init(pageTypeEnum::PAGE_TYPE_JUMBO, threadId);
		}
}
namespace stt
{
  PATL_Data::~ PATL_Data ()
                     {
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("~PATL_Data %p\n", this);
		#endif
		}
}
namespace stt
{
  std::atomic <int> ThreadSafePageAllocatorImpl::dbg_totalPagesAllocated = 0;
}
namespace stt
{
  ThreadSafePageAllocatorImpl::ThreadSafePageAllocatorImpl ()
                                      {
		PageGlobalFreeList.init (pageTypeEnum::PAGE_TYPE_NORMAL, 10);
		JumboGlobalFreeList.init (pageTypeEnum::PAGE_TYPE_JUMBO, 1);
		
		
		initThreadLocalPools(); // init for this thread
		}
}
namespace stt
{
  ThreadSafePageAllocatorImpl::~ ThreadSafePageAllocatorImpl ()
                                       {
		cleanupBackendPools();
		}
}
namespace stt
{
  uint8_t * ThreadSafePageAllocatorImpl::raw_alloc (uint64_t const sz)
                                                     { return new uint8_t[sz]; }
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::raw_free (uint8_t * ptr, uint64_t const sz)
                                                              { delete[] ptr; }
}
namespace stt
{
  ThreadSafePageAllocatorImpl & ThreadSafePageAllocatorImpl::get ()
                                                  {
		static ThreadSafePageAllocatorImpl Instance;
		return Instance;
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::initThreadLocalPools ()
                                    {
		PATL_Data* r = mTls.getTlsData();
		if (!r)
			mTls.setTlsData(new PATL_Data);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::cleanupThreadLocalPools ()
                                       {
		PATL_Data* r = ThreadSafePageAllocatorImpl::get().mTls.getTlsData();
		if (r) delete r;
		mTls.setTlsData(NULL);
		}
}
namespace stt
{
  uint32_t ThreadSafePageAllocatorImpl::cleanupBackendPools ()
                                       {
		uint32_t r = 0;
		r += PageGlobalFreeList.freeAllToSystem();
		r += JumboGlobalFreeList.freeAllToSystem();
		return r;
		}
}
namespace stt
{
  PATL_Data * ThreadSafePageAllocatorImpl::getThreadLocalPools ()
                                         {
		return mTls.getTlsData();
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::allocPages (pageU * * pages, uint32_t const nPages)
                                                              {
		PATL_Data* LA = getThreadLocalPools();
		if (!LA) {
			// free after TL shutdown!
			perf_warning("PERF: allocPages() without thread_local pools, using global pool");
			PageGlobalFreeList.bulkFetch((pageHeader**) pages, nPages);
			return;
			}
		LA->pageAlloc.allocPages((pageHeader**) pages, nPages);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::freePages (pageU * * pages, uint32_t const nPages)
                                                             {
		PATL_Data* LA = getThreadLocalPools();
		if (!LA) {
			// free after TL shutdown!
			perf_warning("PERF: freePages() without thread_local pools, using global pool");
			PageGlobalFreeList.freePages((pageHeader**) pages, nPages);
			return;
			}
		LA->pageAlloc.freePages((pageHeader**) pages, nPages);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::freePagesList (pageU * pageList)
                                            {
		PATL_Data* LA = getThreadLocalPools();
		if (!LA) {
			// free after TL shutdown!
			perf_warning("PERF: freePagesList() without thread_local pools, using global pool");
			PageGlobalFreeList.atomicMerge((pageHeader*) pageList);
			return;
			}
		LA->pageAlloc.freePagesList((pageHeader*) pageList);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::allocJumboPages (jumboPageU * * pages, uint32_t const nPages)
                                                                        {
		PATL_Data* LA = getThreadLocalPools();
		if (!LA) {
			// free after TL shutdown!
			perf_warning("PERF: allocJumboPages() without thread_local pools, using global pool");
			JumboGlobalFreeList.bulkFetch((pageHeader**) pages, nPages);
			return;
			}
		LA->jumboPageAlloc.allocPages((pageHeader**) pages, nPages);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::freeJumboPages (jumboPageU * * pages, uint32_t const nPages)
                                                                       {
		PATL_Data* LA = getThreadLocalPools();
		if (!LA) {
			// free after TL shutdown!
			perf_warning("PERF: freeJumboPages() without thread_local pools, using global pool");
			JumboGlobalFreeList.freePages((pageHeader**) pages, nPages);
			return;
			}
		LA->jumboPageAlloc.freePages((pageHeader**) pages, nPages);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::freeJumboPagesList (jumboPageU * pageList)
                                                      {
		PATL_Data* LA = getThreadLocalPools();
		if (!LA) {
			// free after TL shutdown!
			perf_warning("PERF: freeJumboPagesList() without thread_local pools, using global pool");
			JumboGlobalFreeList.atomicMerge((pageHeader*) pageList);
			return;
			}
		LA->jumboPageAlloc.freePagesList((pageHeader*) pageList);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::systemAllocate (pageTypeEnum const mPageType, uint32_t const nPagesTotal, uint32_t const nSplit, pageHeader * * groupA, pageHeader * * groupB)
                                                                                                                                                              {
		// Group A & B are pointers to pointers, NOT arrays of pointers
		if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
			systemAllocate_impl(sizeof(pageU), nPagesTotal, nSplit, groupA, groupB);
		else if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
			systemAllocate_impl(sizeof(jumboPageU), nPagesTotal, nSplit, groupA, groupB);
		else
			STT_STL_ABORT();
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::systemAllocate_impl (uint32_t const sizeofPageType, uint32_t const nPagesTotal, uint32_t const nSplit, pageHeader * * groupA, pageHeader * * groupB)
                                                                                                                                                                    {
		// Group A & B are pointers to pointers, NOT arrays of pointers
		// allocates at least nPagesTotal, and returns (nSplit) into linked list groupA and the rest into linked list groupB
				
		pageHeader* ph[nPagesTotal];
		ph[0] = (pageHeader*) raw_alloc(sizeofPageType);
		for (uint i = 1; i < nPagesTotal; ++i) {
			ph[i] = (pageHeader*) raw_alloc(sizeofPageType);
			ph[i-1]->next = ph[i];
			}
		ph[nPagesTotal-1]->next = NULL;
		
		// are we splitting?
		if (nSplit == nPagesTotal) {
			// only goes here if batchSize == 0
			*groupA = ph[0];
			*groupB = NULL;
			ph[0]->cachedWorkingEnd = ph[nSplit-1];
			}
		else if (nSplit > 0) {
			// this is the normal branch
			ph[nSplit-1]->next = NULL;
			*groupA = ph[0];
			*groupB = ph[nSplit];
			
			ph[0]->cachedWorkingEnd = ph[nSplit-1];
			ph[nSplit]->cachedWorkingEnd = ph[nPagesTotal-1];
			
			#if STT_STL_DEBUG_PAGE
			//stt_dbg_log("SystemAllocate: groupB:\n");
			//int c = 0;
			//(*groupB)->endCountingDumping(c);
			#endif
			}
		else {
			*groupA = NULL;
			*groupB = ph[0];
			ph[0]->cachedWorkingEnd = ph[nPagesTotal-1];
			}
		
		#if STT_STL_TRACK_SYSTEM_ALLOCATIONS
			dbg_totalPagesAllocated += nPagesTotal;
		#endif
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("SystemAllocate: Allocated %i (%i) pages, starting with %p, dbg_totalPagesAllocated: %i\n", nPagesTotal, nSplit, ph[0], int(dbg_totalPagesAllocated));
		#endif
		}
}
namespace stt
{
  uint32_t ThreadSafePageAllocatorImpl::systemFreeList (pageHeader * head)
                                                         {
		// nPagesTotal is only tracked ifdef STT_STL_TRACK_SYSTEM_ALLOCATIONS
		uint32_t nPagesTotal = 0;
		pageHeader* w = head;
		while (w) {
			pageHeader* n = w->next;
			raw_free((uint8_t*) w, 0);
			w = n;
			#if STT_STL_TRACK_SYSTEM_ALLOCATIONS
				nPagesTotal++;
			#endif
			}
			
		#if STT_STL_TRACK_SYSTEM_ALLOCATIONS
			dbg_totalPagesAllocated -= nPagesTotal;
		#endif
		#if STT_STL_DEBUG_PAGE
			stt_dbg_log("SystemAllocate: Freeing %i pages, total allocated: %i\n", nPagesTotal, int(dbg_totalPagesAllocated));
		#endif
		return nPagesTotal;
		}
}
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_mt_page_allocator_impl
#endif //STT_STL_IMPL_IMPL
// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// mt_page_allocator.hh
//

#ifndef LZZ_mt_page_allocator_hh
#define LZZ_mt_page_allocator_hh
#define LZZ_INLINE inline
namespace stt
{
  class ThreadSafePageAllocator
  {
  public:
    static void initThreadLocalPools ();
    static void cleanupThreadLocalPools ();
    static uint32_t cleanupBackendPools ();
    static PATL_Data * getThreadLocalPools ();
    static ThreadLocalPagePool * getThreadLocalPool (pageTypeEnum const pe);
    static BackendPagePool * getBackendPool (pageTypeEnum const pe);
    static pageU * allocPage ();
    static void freePage (pageU * page);
    static void allocPages (pageU * * pages, uint32_t const nPages);
    static void freePages (pageU * * pages, uint32_t const nPages);
    static void freePagesList (pageU * pageLinkedList);
    static jumboPageU * allocJumboPage ();
    static void freeJumboPage (jumboPageU * page);
    static void allocJumboPages (jumboPageU * * pages, uint32_t const nPages);
    static void freeJumboPages (jumboPageU * * pages, uint32_t const nPages);
    static void freeJumboPagesList (jumboPageU * pageLinkedList);
    static int dbg_getNPagesAllocated ();
  };
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    T * allocGeneric ();
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    void freeGeneric (T * t);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    void allocGenericBatch (T * * t, uint32_t const n);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    void freeGenericBatch (T * * t, uint32_t const n);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    void freeGenericList (T * t);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    pageU * allocGeneric ();
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    void freeGeneric (pageU * t);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    void allocGenericBatch (pageU * * t, uint32_t const n);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    void freeGenericBatch (pageU * * t, uint32_t const n);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    void freeGenericList (pageU * t);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    jumboPageU * allocGeneric ();
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    void freeGeneric (jumboPageU * t);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    void allocGenericBatch (jumboPageU * * t, uint32_t const n);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    void freeGenericBatch (jumboPageU * * t, uint32_t const n);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    void freeGenericList (jumboPageU * t);
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    T * allocGeneric ()
                                                    { STT_STL_ABORT(); return NULL; }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    void freeGeneric (T * t)
                                                    { STT_STL_ABORT(); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    void allocGenericBatch (T * * t, uint32_t const n)
                                                                             { STT_STL_ABORT(); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    void freeGenericBatch (T * * t, uint32_t const n)
                                                                             { STT_STL_ABORT(); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <typename T>
    void freeGenericList (T * t)
                                                        { STT_STL_ABORT(); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE pageU * allocGeneric ()
                                                     { return ThreadSafePageAllocator::allocPage(); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE void freeGeneric (pageU * t)
                                                     { ThreadSafePageAllocator::freePage(t); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE void allocGenericBatch (pageU * * t, uint32_t const n)
                                                                              { ThreadSafePageAllocator::allocPages(t, n); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE void freeGenericBatch (pageU * * t, uint32_t const n)
                                                                              { ThreadSafePageAllocator::freePages(t, n); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE void freeGenericList (pageU * t)
                                                         { ThreadSafePageAllocator::freePagesList(t); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE jumboPageU * allocGeneric ()
                                                          { return ThreadSafePageAllocator::allocJumboPage(); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE void freeGeneric (jumboPageU * t)
                                                          { ThreadSafePageAllocator::freeJumboPage(t); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE void allocGenericBatch (jumboPageU * * t, uint32_t const n)
                                                                                   { ThreadSafePageAllocator::allocJumboPages(t, n); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE void freeGenericBatch (jumboPageU * * t, uint32_t const n)
                                                                                   { ThreadSafePageAllocator::freeJumboPages(t, n); }
  }
}
namespace stt
{
  namespace ThreadSafePageAllocatorTemplates
  {
    template <>
    LZZ_INLINE void freeGenericList (jumboPageU * t)
                                                              { ThreadSafePageAllocator::freeJumboPagesList(t); }
  }
}
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_mt_page_allocator
#define STT_STL_IMPL_DOUBLE_GUARD_mt_page_allocator
#define LZZ_OVERRIDE
// mt_page_allocator.cpp
//

namespace stt {
	int dbg_getNPagesAllocated_forward() { return ThreadSafePageAllocator::dbg_getNPagesAllocated(); }
	}
#define LZZ_INLINE inline
namespace stt
{
  void ThreadSafePageAllocator::initThreadLocalPools ()
                                           {
		// MUST be called on thread startup!
		ThreadSafePageAllocatorImpl::get().initThreadLocalPools();
		}
}
namespace stt
{
  void ThreadSafePageAllocator::cleanupThreadLocalPools ()
                                              {
		// MUST be called on thread end!
		ThreadSafePageAllocatorImpl::get().cleanupThreadLocalPools();
		}
}
namespace stt
{
  uint32_t ThreadSafePageAllocator::cleanupBackendPools ()
                                              {
		// Releases all pages owned by the backend pool back to system memory
		// if macro STT_STL_TRACK_SYSTEM_ALLOCATIONS is defined then returns number of pages returned		
		return ThreadSafePageAllocatorImpl::get().cleanupBackendPools();
		}
}
namespace stt
{
  PATL_Data * ThreadSafePageAllocator::getThreadLocalPools ()
                                                {
		return ThreadSafePageAllocatorImpl::get().getThreadLocalPools();
		}
}
namespace stt
{
  ThreadLocalPagePool * ThreadSafePageAllocator::getThreadLocalPool (pageTypeEnum const pe)
                                                                              {
		PATL_Data* PD = ThreadSafePageAllocatorImpl::get().getThreadLocalPools();
		if (!PD) return NULL;
		if (pe == pageTypeEnum::PAGE_TYPE_NORMAL) return &PD->pageAlloc;
		if (pe == pageTypeEnum::PAGE_TYPE_JUMBO) return &PD->jumboPageAlloc;
		return NULL;
		}
}
namespace stt
{
  BackendPagePool * ThreadSafePageAllocator::getBackendPool (pageTypeEnum const pe)
                                                                      {
		if (pe == pageTypeEnum::PAGE_TYPE_NORMAL) return &ThreadSafePageAllocatorImpl::get().PageGlobalFreeList;
		if (pe == pageTypeEnum::PAGE_TYPE_JUMBO) return &ThreadSafePageAllocatorImpl::get().JumboGlobalFreeList;
		return NULL;
		}
}
namespace stt
{
  pageU * ThreadSafePageAllocator::allocPage ()
                                  {
		// Allocates a single pageU
		pageU* arr[1];
		ThreadSafePageAllocatorImpl::get().allocPages(&arr[0], 1);
		return arr[0];
		}
}
namespace stt
{
  void ThreadSafePageAllocator::freePage (pageU * page)
                                          {
		pageU* arr[1];
		arr[0] = page;
		ThreadSafePageAllocatorImpl::get().freePages(&arr[0], 1);
		}
}
namespace stt
{
  void ThreadSafePageAllocator::allocPages (pageU * * pages, uint32_t const nPages)
                                                                     { ThreadSafePageAllocatorImpl::get().allocPages(pages, nPages); }
}
namespace stt
{
  void ThreadSafePageAllocator::freePages (pageU * * pages, uint32_t const nPages)
                                                                     { ThreadSafePageAllocatorImpl::get().freePages(pages, nPages); }
}
namespace stt
{
  void ThreadSafePageAllocator::freePagesList (pageU * pageLinkedList)
                                                         { ThreadSafePageAllocatorImpl::get().freePagesList(pageLinkedList); }
}
namespace stt
{
  jumboPageU * ThreadSafePageAllocator::allocJumboPage ()
                                            {
		// Allocates a single pageU
		jumboPageU* arr[1];
		ThreadSafePageAllocatorImpl::get().allocJumboPages(&arr[0], 1);
		return arr[0];
		}
}
namespace stt
{
  void ThreadSafePageAllocator::freeJumboPage (jumboPageU * page)
                                                    {
		jumboPageU* arr[1];
		arr[0] = page;
		ThreadSafePageAllocatorImpl::get().freeJumboPages(&arr[0], 1);
		}
}
namespace stt
{
  void ThreadSafePageAllocator::allocJumboPages (jumboPageU * * pages, uint32_t const nPages)
                                                                               { ThreadSafePageAllocatorImpl::get().allocJumboPages(pages, nPages); }
}
namespace stt
{
  void ThreadSafePageAllocator::freeJumboPages (jumboPageU * * pages, uint32_t const nPages)
                                                                               { ThreadSafePageAllocatorImpl::get().freeJumboPages(pages, nPages); }
}
namespace stt
{
  void ThreadSafePageAllocator::freeJumboPagesList (jumboPageU * pageLinkedList)
                                                                   { ThreadSafePageAllocatorImpl::get().freeJumboPagesList(pageLinkedList); }
}
namespace stt
{
  int ThreadSafePageAllocator::dbg_getNPagesAllocated ()
                                            { return ThreadSafePageAllocatorImpl::dbg_totalPagesAllocated; }
}
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_mt_page_allocator
#endif //STT_STL_IMPL_IMPL
// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// page.hh
//

#ifndef LZZ_page_hh
#define LZZ_page_hh
#ifndef STT_PAGE_HEADER_SIZE
	#define STT_PAGE_HEADER_SIZE 64
#endif
#ifndef STT_PAGE_SIZE
	#define STT_PAGE_SIZE 4080	// this makes alignement better 
#endif
#ifndef STT_JUMBO_PAGE_SIZE
	#define STT_JUMBO_PAGE_SIZE 65520
#endif

	
#define LZZ_INLINE inline
namespace stt
{
  enum pageTypeEnum
  {
    PAGE_TYPE_NORMAL,
    PAGE_TYPE_JUMBO,
    PAGE_TYPE_UNSET
  };
}
namespace stt
{
  char const * pageTypeEnumToString (pageTypeEnum const pt);
}
namespace stt
{
  struct pageHeader
  {
    pageHeader * next;
    pageHeader * cachedWorkingEnd;
    uint64_t allocationInfo;
    uint32_t localSize;
    uint32_t totalSize;
    uint64_t (userData) [4];
    void initToZero ();
    void appendList (pageHeader * other);
    pageHeader * splitList (uint32_t const nPages);
    static pageHeader * buildList (pageHeader * * pages, uint32_t const nPages);
    pageHeader * end ();
    pageHeader * endCounting (int & countOut);
    pageHeader * endCountingDumping (int & countOut);
    int listLength ();
    uint8_t * toPayload ();
    static pageHeader * fromPayload (uint8_t * ptr);
  };
}
namespace stt
{
  template <unsigned int SIZE, pageTypeEnum ET>
  union pageTemplate
  {
    pageHeader ph;
    uint8_t (_data) [SIZE];
    void initHeader ();
    constexpr uint8_t * ptr ();
    constexpr uint8_t const * ptr () const;
    static constexpr size_t capacity ();
    static constexpr size_t storageSize ();
    static constexpr pageTypeEnum getPageType ();
  };
}
namespace stt
{
  typedef pageTemplate <STT_PAGE_SIZE, pageTypeEnum::PAGE_TYPE_NORMAL> pageU;
}
namespace stt
{
  typedef pageTemplate <STT_JUMBO_PAGE_SIZE, pageTypeEnum::PAGE_TYPE_JUMBO> jumboPageU;
}
namespace stt
{
  LZZ_INLINE void pageHeader::initToZero ()
                                         {
			//allocator = NULL;
			next = NULL;
			cachedWorkingEnd = NULL;
			allocationInfo = 0;
			localSize = 0;
			totalSize = 0;
			userData[0] = 0;
			userData[1] = 0;
			userData[2] = 0;
			userData[3] = 0;
			}
}
namespace stt
{
  LZZ_INLINE uint8_t * pageHeader::toPayload ()
                                            {
			uint8_t* ptr = (uint8_t*) this;
			return &ptr[STT_PAGE_HEADER_SIZE];
			}
}
namespace stt
{
  LZZ_INLINE pageHeader * pageHeader::fromPayload (uint8_t * ptr)
                                                                    {
			// Reverse operation of pageU::ptr(), takes a page's data pointer and returns the address of the header
			return (pageHeader*) &ptr[-STT_PAGE_HEADER_SIZE];
			}
}
namespace stt
{
  template <unsigned int SIZE, pageTypeEnum ET>
  LZZ_INLINE void pageTemplate <SIZE, ET>::initHeader ()
                                         { ph.initToZero(); ph.allocationInfo = SIZE; }
}
namespace stt
{
  template <unsigned int SIZE, pageTypeEnum ET>
  constexpr uint8_t * pageTemplate <SIZE, ET>::ptr ()
                                                          { return &_data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  template <unsigned int SIZE, pageTypeEnum ET>
  constexpr uint8_t const * pageTemplate <SIZE, ET>::ptr () const
                                                          { return &_data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  template <unsigned int SIZE, pageTypeEnum ET>
  constexpr size_t pageTemplate <SIZE, ET>::capacity ()
                                                        { return SIZE - STT_PAGE_HEADER_SIZE;  }
}
namespace stt
{
  template <unsigned int SIZE, pageTypeEnum ET>
  constexpr size_t pageTemplate <SIZE, ET>::storageSize ()
                                                           { return SIZE;  }
}
namespace stt
{
  template <unsigned int SIZE, pageTypeEnum ET>
  constexpr pageTypeEnum pageTemplate <SIZE, ET>::getPageType ()
                                                                 { return ET; }
}
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_page
#define STT_STL_IMPL_DOUBLE_GUARD_page
#define LZZ_OVERRIDE
// page.cpp
//


namespace stt {
	static_assert(sizeof(pageHeader) <= STT_PAGE_HEADER_SIZE);
	}
#define LZZ_INLINE inline
namespace stt
{
  char const * pageTypeEnumToString (pageTypeEnum const pt)
                                                                 {
		switch (pt) {
			case pageTypeEnum::PAGE_TYPE_NORMAL: return "Normal";
			case pageTypeEnum::PAGE_TYPE_JUMBO: return "Jumbo";
			default: return "Unset";
			}
		}
}
namespace stt
{
  void pageHeader::appendList (pageHeader * other)
                                                   {
			// appends other to this list
			// assumes cachedWorkingEnd is a valid value for both this and othe
			// assumes other is not null
			cachedWorkingEnd->next = other;
			cachedWorkingEnd = other->cachedWorkingEnd;
			}
}
namespace stt
{
  pageHeader * pageHeader::splitList (uint32_t const nPages)
                                                             {
			// assumes cachedWorkingEnd is a valid value for this
			// if this is too short then returns NULL
			pageHeader* w = this;
			uint32_t cnt = 1;
			while (w->next && (cnt < nPages)) {
				cnt++;
				w = w->next;
				}
			// w should now be the end of this list
			// and w->next should be the start of next
			if (!w) return NULL; // fail split
			if (!w->next) return NULL; // fail split
			
			pageHeader* r = w->next;
			r->cachedWorkingEnd = cachedWorkingEnd;
			w->next = NULL;
			cachedWorkingEnd = w;
			return r;
			}
}
namespace stt
{
  pageHeader * pageHeader::buildList (pageHeader * * pages, uint32_t const nPages)
                                                                                        {
			// assembles pages into a linked list, returns the head
			if (!nPages) return NULL;
			for (uint32_t i = 0; i < nPages-1; ++i) {
				pages[i]->next = pages[i+1];
				}
			pages[nPages-1]->next = NULL;
			pages[0]->cachedWorkingEnd = pages[nPages-1];
			return pages[0];
			}
}
namespace stt
{
  pageHeader * pageHeader::end ()
                                  {
			// manually traverses to the end
			pageHeader* w = this;
			while (w->next) { w = w->next; }
			return w;
			}
}
namespace stt
{
  pageHeader * pageHeader::endCounting (int & countOut)
                                                       {
			// manually traverses to the end, counts number of pages
			pageHeader* w = this;
			countOut++;
			while (w->next) { w = w->next; countOut++; }
			return w;
			}
}
namespace stt
{
  pageHeader * pageHeader::endCountingDumping (int & countOut)
                                                              {
			pageHeader* w = this;
			countOut++;
			while (w->next) {
				w = w->next;
				#ifdef STT_STL_DEBUG
				stt_dbg_log("\t\tendCountingDumping %p %i deep is %p\n", this, countOut, w);
				#endif
				countOut++; 
				}
			return w;
			}
}
namespace stt
{
  int pageHeader::listLength ()
                                 {
			int cnt = 0;
			endCounting(cnt);
			return cnt;
			}
}
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_page
#endif //STT_STL_IMPL_IMPL
// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// page_queue.hh
//

#ifndef LZZ_page_queue_hh
#define LZZ_page_queue_hh
namespace stt {
	template<typename T, typename P>
	struct pageQueueImpl;
	
	template <typename T>
	using pageQueue = pageQueueImpl<T,pageU>;
	}

#define STT_PAGEQUEUE_MVSEM pageQueueImpl&&
#define LZZ_INLINE inline
namespace stt
{
  template <typename T, typename P>
  struct pageQueueImpl
  {
    P * head;
    P * tail;
    struct iterator
    {
      T * ptr;
      T * localEnd;
      P * currentPage;
      void init (P * page);
      void incr ();
      void incr_nonInline ();
      typename pageQueueImpl <T,P>::iterator & operator ++ ();
      bool operator != (iterator const & other) const;
      T operator * ();
    };
    pageQueueImpl ();
    ~ pageQueueImpl ();
    void move_impl (STT_PAGEQUEUE_MVSEM other);
    pageQueueImpl (STT_PAGEQUEUE_MVSEM other);
    pageQueueImpl <T,P> & operator = (STT_PAGEQUEUE_MVSEM other);
  private:
    pageQueueImpl (pageQueueImpl const & other);
    pageQueueImpl & operator = (pageQueueImpl const & other);
  public:
    static P * allocPage ();
    static P * allocPages (uint32_t const nPages);
    static void freePage (P * page);
    static void freePagesList (P * pageList);
    void extendTailIfRequired ();
    void extendTail ();
    P * trueTail () const;
    static constexpr size_t pageLocalCapacity ();
    static constexpr T * pagePtr (P * const p);
    static constexpr T const * pagePtr (P const * const p);
    uint32_t size () const;
    uint32_t numPages () const;
    void clear ();
    static void call_destructors_for_page (P * t);
    void clearKeepingFirstPage ();
    void swap (pageQueueImpl & other);
    void concatenate (STT_PAGEQUEUE_MVSEM other);
    void reserve (uint32_t const sz);
    T * push_back (T const & t);
    T * push_back (T&& t);
    iterator iter_at (uint32_t const idx);
    iterator begin ();
    iterator end ();
  };
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::iterator::init (P * page)
                                           {
				currentPage = page;
				if (currentPage) {
					ptr = pageQueueImpl::pagePtr(currentPage);
					localEnd = &ptr[currentPage->ph.localSize];
					}
				else {
					ptr = NULL;
					localEnd = NULL;
					}
				}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE void pageQueueImpl <T, P>::iterator::incr ()
                                           {
				if (ptr) // do not increment a null pointer
					ptr++;
				while (ptr == localEnd && currentPage) // if we are at the end of a page then increment to the next non-empty page
					incr_nonInline();
				}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::iterator::incr_nonInline ()
                                              {
				currentPage = (P*) currentPage->ph.next;
				if (currentPage) {
					ptr = pageQueueImpl::pagePtr(currentPage);
					localEnd = &ptr[currentPage->ph.localSize];
					}
				else {
					ptr = NULL;
					localEnd = NULL;
					}
				}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE typename pageQueueImpl <T,P>::iterator & pageQueueImpl <T, P>::iterator::operator ++ ()
                                                                                   {
				incr();
				return *this;
				}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE bool pageQueueImpl <T, P>::iterator::operator != (iterator const & other) const
                                                                             { return ptr != other.ptr; }
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE T pageQueueImpl <T, P>::iterator::operator * ()
                                              { return *ptr; }
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE pageQueueImpl <T, P>::pageQueueImpl ()
    : head (NULL), tail (NULL)
                                                                 {}
}
namespace stt
{
  template <typename T, typename P>
  pageQueueImpl <T, P>::~ pageQueueImpl ()
                                 { clear(); }
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE void pageQueueImpl <T, P>::move_impl (STT_PAGEQUEUE_MVSEM other)
                                                                 { head = other.head; tail = other.tail; other.head = NULL; other.tail = NULL; }
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE pageQueueImpl <T, P>::pageQueueImpl (STT_PAGEQUEUE_MVSEM other)
                                                                { move_impl(std::move(other)); }
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE pageQueueImpl <T,P> & pageQueueImpl <T, P>::operator = (STT_PAGEQUEUE_MVSEM other)
                                                                                 { clear(); move_impl(std::move(other)); return *this; }
}
namespace stt
{
  template <typename T, typename P>
  P * pageQueueImpl <T, P>::allocPage ()
                                       {
			P* p = ThreadSafePageAllocatorTemplates::allocGeneric<P>();
			p->initHeader();
			return p;
			}
}
namespace stt
{
  template <typename T, typename P>
  P * pageQueueImpl <T, P>::allocPages (uint32_t const nPages)
                                                             {
			if (nPages == 0) return NULL;
			P* store[nPages];
			ThreadSafePageAllocatorTemplates::allocGenericBatch<P>(&store[0], nPages);
			for (uint32_t i = 0; i < nPages; ++i)
				store[i]->initHeader();
			return pageHeader::buildList((pageHeader**) &store[0], nPages); // TBD - buildListAndInit
			}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::freePage (P * page)
                                              {
			ThreadSafePageAllocatorTemplates::freeGeneric<P>(page);
			}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::freePagesList (P * pageList)
                                                       {
			ThreadSafePageAllocatorTemplates::freeGenericList<P>(pageList);
			}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::extendTailIfRequired ()
                                            {
			if (!tail || tail->ph.localSize >= pageLocalCapacity())
				extendTail();
			}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::extendTail ()
                                   {
			if (!tail) {
				head = allocPage();
				tail = head;
				return;
				}
			if (!tail->ph.next)
				tail->ph.next = (pageHeader*) allocPage();
			tail = (P*) tail->ph.next;
			}
}
namespace stt
{
  template <typename T, typename P>
  P * pageQueueImpl <T, P>::trueTail () const
                                    {
			// returns the true end of the linked list
			P* t = tail;
			if (!t) return t;
			while (t->ph.next)
				t = (P*) t->ph.next;
			return t;
			}
}
namespace stt
{
  template <typename T, typename P>
  constexpr size_t pageQueueImpl <T, P>::pageLocalCapacity ()
                                                                         { return P::capacity() / sizeof(T);  }
}
namespace stt
{
  template <typename T, typename P>
  constexpr T * pageQueueImpl <T, P>::pagePtr (P * const p)
                                                                         { return (T*) &p->_data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  template <typename T, typename P>
  constexpr T const * pageQueueImpl <T, P>::pagePtr (P const * const p)
                                                                         { return (const T*) &p->_data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE uint32_t pageQueueImpl <T, P>::size () const
                                             { return head ? head->ph.totalSize : 0; }
}
namespace stt
{
  template <typename T, typename P>
  uint32_t pageQueueImpl <T, P>::numPages () const
                                           { return head ? head->ph.listLength() : 0; }
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::clear ()
                             {
			if constexpr(std::is_trivially_destructible<T>::value) {
				// we don't need to invoke destructors so we can just throw away the linked list
				if (head) {
					head->ph.cachedWorkingEnd = (pageHeader*) trueTail();
					freePagesList(head);
					}
				}
			else {
				// we need to itterate through the linked list and destroy every object
				P* w = head;
				while (w) {
					P* t = w;
					w = (P*) w->ph.next;
					call_destructors_for_page(t);
					freePage(t);
					}
				}
			head = NULL;
			tail = NULL;
			}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::call_destructors_for_page (P * t)
                                                            {
			T* arr = pagePtr(t);
			const uint32_t sz = t->ph.localSize;
			for (uint32_t i = 0; i < sz; ++i)
				arr[i].~T();
			}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::clearKeepingFirstPage ()
                                             {
			// Clears the pageQueue but keeps the first page
			if (head && head->next) {
				pageQueueImpl tmp;
				tmp.head = head->next;
				tmp.head->ph.cachedWorkingEnd = tail;
				tmp.tail = tail;
				tmp.clear();
				head->ph.next = NULL;
				tail = head; 
				if constexpr(!std::is_trivially_destructible<T>::value)
					call_destructors_for_page(head);
				head->ph.localSize = 0;
				head->ph.totalSize = 0;
				}
			}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::swap (pageQueueImpl & other)
                                                {
			std::swap(head, other.head);
			std::swap(tail, other.tail);
			}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::concatenate (STT_PAGEQUEUE_MVSEM other)
                                                            {
			// transfers the other queue to the end of this
			if (!other.head)
				return;
			if (tail) {
				tail->ph.next = (pageHeader*) other.head;
				tail = other.tail;
				}
			else {
				head = other.head;
				tail = other.tail;
				}
			other.head = NULL;
			other.tail = NULL;
			}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE void pageQueueImpl <T, P>::reserve (uint32_t const sz)
                                                       {
			// no-op
			// TBD - allocates pages and links them. Tail is set to the push_back write-head but trueTail() is the end of allocated storage
			if (sz <= size()) return;
			if (tail)
				if (tail->ph.next)
					return; // pages are already preallocated
			
			//                   needed          avaliable in tail page
			const int32_t want = (sz - size()) - (pageLocalCapacity() - tail->ph.localSize);
			if (want <= 0) return; // already capacity avaliable
			uint32_t nPagesToAllocate = want/pageLocalCapacity();
			tail->ph.next = allocPages(nPagesToAllocate);
			}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE T * pageQueueImpl <T, P>::push_back (T const & t)
                                                {
			extendTailIfRequired();
			T* r = new (&(pageQueueImpl::pagePtr(tail)[tail->ph.localSize])) T(t);
			tail->ph.localSize++;
			head->ph.totalSize++;
			return r;
			}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE T * pageQueueImpl <T, P>::push_back (T&& t)
                                                {
			//stt_dbg_log("move semantics!\n");
			extendTailIfRequired();
			T* r = new (&(pageQueueImpl::pagePtr(tail)[tail->ph.localSize])) T(std::move(t));
			tail->ph.localSize++;
			head->ph.totalSize++;
			return r;
			}
}
namespace stt
{
  template <typename T, typename P>
  typename pageQueueImpl <T, P>::iterator pageQueueImpl <T, P>::iter_at (uint32_t const idx)
                                                     {
			// returns an iterator at a specified index
			if (!head) return end();
			if (idx >= size()) return end();
			uint32_t idx2 = idx;
			P* w = head;
			while (w && w->ph.localSize < idx2) {
				idx2 -= w->ph.localSize;
				w = (P*) w->ph.next;
				}
			if (!w) return end();
			iterator it;
			it.init(w);
			it.ptr += idx2;
			return it;
			}
}
namespace stt
{
  template <typename T, typename P>
  typename pageQueueImpl <T, P>::iterator pageQueueImpl <T, P>::begin ()
                                 {
			iterator it;
			it.init(head);
			return  it;
			}
}
namespace stt
{
  template <typename T, typename P>
  typename pageQueueImpl <T, P>::iterator pageQueueImpl <T, P>::end ()
                               {
			iterator it;
			it.init(NULL);
			return  it;
			}
}
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_page_queue
#define STT_STL_IMPL_DOUBLE_GUARD_page_queue
#define LZZ_OVERRIDE
// page_queue.cpp
//

#define LZZ_INLINE inline
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_page_queue
#endif //STT_STL_IMPL_IMPL
// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// page_queue_bump_storage.hh
//

#ifndef LZZ_page_queue_bump_storage_hh
#define LZZ_page_queue_bump_storage_hh
#define STT_PAGEQUEUEBUMPSTORAGE_MVSEM pageQueueBumpStorage&&
#define LZZ_INLINE inline
namespace stt
{
  struct pageQueueBumpStorageOverflowCtr
  {
    pageQueue <string24> overflowStore;
    string_view push_back (char const * str, uint32_t const sz);
    void swap (pageQueueBumpStorageOverflowCtr & other);
    void clear ();
  };
}
namespace stt
{
  template <typename P>
  struct pageQueueBumpStorage : public allocatorI
  {
    typedef uint16_t writeSizeType;
    typedef pageQueueImpl <char,P> pqType;
    pqType store;
    pageQueueBumpStorageOverflowCtr * overflow;
    uint8_t overflowMode;
    static uint8_t const OVERFLOW_MODE_ABORT;
    static uint8_t const OVERFLOW_MODE_TRUNCATE;
    pageQueueBumpStorage ();
    ~ pageQueueBumpStorage ();
    void move_impl (STT_PAGEQUEUEBUMPSTORAGE_MVSEM other);
    pageQueueBumpStorage (STT_PAGEQUEUEBUMPSTORAGE_MVSEM other);
    pageQueueBumpStorage <P> & operator = (STT_PAGEQUEUEBUMPSTORAGE_MVSEM other);
  private:
    pageQueueBumpStorage (pageQueueBumpStorage const & other);
    pageQueueBumpStorage & operator = (pageQueueBumpStorage const & other);
  public:
    void swapOverflow (pageQueueBumpStorageOverflowCtr * otherOverlow);
    template <typename T>
    T * serialise (T const & t);
    uint8_t * allocate (alloc_size_t const size) noexcept;
    void deallocate (uint8_t * ptr, alloc_size_t const size) noexcept;
    string_view checkOverflow (char const * str, uint32_t const size, uint32_t const wantsSize);
    string_view push_back (string_view const & sv);
    string_view push_back (char const * str, uint32_t const size);
    struct pushBackLookupHint
    {
      P * page;
      uint32_t avaliableSize;
      pushBackLookupHint ();
      void reset ();
    };
    string_view push_back_compact (string_view const & sv, pushBackLookupHint * hint = NULL);
    string_view push_back_compact (char const * str, uint32_t const size, pushBackLookupHint * hint = NULL);
    void swap (pageQueueBumpStorage & other);
    void clear ();
    void clearKeepingFirstPage ();
    uint32_t remainingBytesIn (P * t) const;
    static constexpr uint32_t maxWriteSize ();
    static string_view writeBufferRaw (P * page, char const * str, writeSizeType const size);
  };
}
namespace stt
{
  template <typename P>
  uint8_t const pageQueueBumpStorage <P>::OVERFLOW_MODE_ABORT = 0;
}
namespace stt
{
  template <typename P>
  uint8_t const pageQueueBumpStorage <P>::OVERFLOW_MODE_TRUNCATE = 1;
}
namespace stt
{
  template <typename P>
  pageQueueBumpStorage <P>::pageQueueBumpStorage ()
                                       { overflow = NULL; overflowMode = OVERFLOW_MODE_ABORT; }
}
namespace stt
{
  template <typename P>
  pageQueueBumpStorage <P>::~ pageQueueBumpStorage ()
                                        { if (overflow) overflow->clear(); }
}
namespace stt
{
  template <typename P>
  void pageQueueBumpStorage <P>::move_impl (STT_PAGEQUEUEBUMPSTORAGE_MVSEM other)
                                                                     {
			store.move_impl(std::move(store.other));
			swapOverflow(other.overflow);
			overflowMode = other.overflowMode;
			}
}
namespace stt
{
  template <typename P>
  LZZ_INLINE pageQueueBumpStorage <P>::pageQueueBumpStorage (STT_PAGEQUEUEBUMPSTORAGE_MVSEM other)
                                                                                  { move_impl(other); }
}
namespace stt
{
  template <typename P>
  LZZ_INLINE pageQueueBumpStorage <P> & pageQueueBumpStorage <P>::operator = (STT_PAGEQUEUEBUMPSTORAGE_MVSEM other)
                                                                                                 { move_impl(other); return *this; }
}
namespace stt
{
  template <typename P>
  void pageQueueBumpStorage <P>::swapOverflow (pageQueueBumpStorageOverflowCtr * otherOverlow)
                                                                                  {
			if ((!overflow) && (!otherOverlow)) return;
			if (overflow && otherOverlow) {
				overflow->swap(*otherOverlow);
				return;
				}
			STT_STL_ASSERT(false, "overflow storage is assigned for one container but not the other");
			}
}
namespace stt
{
  template <typename P>
  template <typename T>
  T * pageQueueBumpStorage <P>::serialise (T const & t)
                                          {
			// writes arbitary object data to this
			// note that if (OVERFLOW_MODE_TRUNCATE) then T might be truncated!
			static_assert(stt::is_pod<T>::value);
			string_view r = push_back((const char*) &t, sizeof(T));
			return (T*) r.data();
			}
}
namespace stt
{
  template <typename P>
  LZZ_INLINE uint8_t * pageQueueBumpStorage <P>::allocate (alloc_size_t const size) noexcept
                                                                            {
			string_view r = push_back(NULL, size);
			return (uint8_t*) r.data();
			}
}
namespace stt
{
  template <typename P>
  LZZ_INLINE void pageQueueBumpStorage <P>::deallocate (uint8_t * ptr, alloc_size_t const size) noexcept
                                                                                        {}
}
namespace stt
{
  template <typename P>
  string_view pageQueueBumpStorage <P>::checkOverflow (char const * str, uint32_t const size, uint32_t const wantsSize)
                                                                                                          {
			// Is this string too big to fit on a page? If so then throw it into a string object
			constexpr uint32_t maxSize = maxWriteSize();
			if (wantsSize > maxSize) {
				if (overflow) {
					return overflow->push_back(str, size);
					}
				else {
					if (overflowMode == OVERFLOW_MODE_ABORT)
						stt::error::array_out_of_bounds(wantsSize, maxSize);
					if (overflowMode == OVERFLOW_MODE_TRUNCATE)
						return push_back(str, maxSize - sizeof(writeSizeType));
					}
				}
			return string_view(NULL,0);
			}
}
namespace stt
{
  template <typename P>
  LZZ_INLINE string_view pageQueueBumpStorage <P>::push_back (string_view const & sv)
                                                                    {
			return push_back(sv.data(), sv.size());
			}
}
namespace stt
{
  template <typename P>
  string_view pageQueueBumpStorage <P>::push_back (char const * str, uint32_t const size)
                                                                            {
			// Fast - tacks on the string at the end
			if (!size) return stt::string_view(NULL, 0);
			const uint32_t wantsSize = size + sizeof(writeSizeType);

			string_view r = checkOverflow(str, size, wantsSize);
			if (r.data()) return r;
			
			store.extendTailIfRequired();
			if (remainingBytesIn(store.tail) < wantsSize)
				store.extendTail();
			return writeBufferRaw(store.tail, str, size);
			}
}
namespace stt
{
  template <typename P>
  LZZ_INLINE pageQueueBumpStorage <P>::pushBackLookupHint::pushBackLookupHint ()
                                                    { reset(); }
}
namespace stt
{
  template <typename P>
  LZZ_INLINE void pageQueueBumpStorage <P>::pushBackLookupHint::reset ()
                                            { page = NULL; avaliableSize = 0; }
}
namespace stt
{
  template <typename P>
  LZZ_INLINE string_view pageQueueBumpStorage <P>::push_back_compact (string_view const & sv, pushBackLookupHint * hint)
                                                                                                             {
			return push_back_compact(sv.data(), sv.size(), hint);
			}
}
namespace stt
{
  template <typename P>
  string_view pageQueueBumpStorage <P>::push_back_compact (char const * str, uint32_t const size, pushBackLookupHint * hint)
                                                                                                                     {
			// Slow - itterates through list to find first page that'll fit this string and puts there
			// usage: 1. `push_back_compact(str, size);` or
			//        2. `pushBackLookupHint hint; for (each_string) { push_back_compact(str, size, &hint); }`
			// if hint is non-null then start searching from (*hint). This optimises for the case in a loop where a
			// big alloc causes a large gap in the middle of the list that can be filled with small 
			if (!size) return stt::string_view(NULL, 0);
			const uint32_t wantsSize = size + sizeof(writeSizeType);
			
			string_view r = checkOverflow(str, size, wantsSize);
			if (r.data()) return r;
			
			P* page = hint ? hint->page : store.head;
			
			while (page) {
				uint32_t remainingBytes = remainingBytesIn(page);
				if (hint) {
					// update biggest free-space page if avaliable
					if (remainingBytes > hint->avaliableSize) {
						hint->page = page;
						hint->avaliableSize = remainingBytes;
						}
					}
				if (remainingBytes >= wantsSize) {
					if (hint && hint->page == page)
						hint->avaliableSize -= wantsSize;
					return writeBufferRaw(page, str, size);
					}
				page = (P*) page->ph.next;
				}
			if (hint) {
				hint->page = NULL; // nothing fit so lookup again next insert
				hint->avaliableSize = 0;
				}
			// fallback to tail push_back
			return push_back(str, size);
			}
}
namespace stt
{
  template <typename P>
  LZZ_INLINE void pageQueueBumpStorage <P>::swap (pageQueueBumpStorage & other)
                                                              { store.swap(other.store); swapOverflow(other.overflow); }
}
namespace stt
{
  template <typename P>
  LZZ_INLINE void pageQueueBumpStorage <P>::clear ()
                                    { store.clear(); if (overflow) overflow->clear(); }
}
namespace stt
{
  template <typename P>
  LZZ_INLINE void pageQueueBumpStorage <P>::clearKeepingFirstPage ()
                                                    { store.clearKeepingFirstPage(); if (overflow) overflow->clear(); }
}
namespace stt
{
  template <typename P>
  LZZ_INLINE uint32_t pageQueueBumpStorage <P>::remainingBytesIn (P * t) const
                                                             { return store.pageLocalCapacity() - t->ph.localSize; }
}
namespace stt
{
  template <typename P>
  LZZ_INLINE constexpr uint32_t pageQueueBumpStorage <P>::maxWriteSize ()
                                                                     {
			 // max size that can be stored without overflow
			return ((writeSizeType(-1) > pqType::pageLocalCapacity()) ? writeSizeType(-1) : pqType::pageLocalCapacity()) - sizeof(writeSizeType);
			}
}
namespace stt
{
  template <typename P>
  string_view pageQueueBumpStorage <P>::writeBufferRaw (P * page, char const * str, writeSizeType const size)
                                                                                                       {
			char* ptr = &pqType::pagePtr(page)[page->ph.localSize];
			*((writeSizeType*) ptr) = size;
			ptr += sizeof(writeSizeType);
			
			if (str) //only copy if this is non null, otherwise leave uninitalised
				stt_memcpy((uint8_t*) ptr, (const uint8_t*) str, size);
			
			page->ph.localSize += size + sizeof(writeSizeType);
			
			//if (page->ph.next) // debug tail corruption REMOVE ME
			//	abort();
			
			return string_view(ptr, size);
			}
}
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_page_queue_bump_storage
#define STT_STL_IMPL_DOUBLE_GUARD_page_queue_bump_storage
#define LZZ_OVERRIDE
// page_queue_bump_storage.cpp
//

#define LZZ_INLINE inline
namespace stt
{
  string_view pageQueueBumpStorageOverflowCtr::push_back (char const * str, uint32_t const sz)
                                                                           {
			string24 * r;
			if (str)
				r = overflowStore.push_back(string24(str, sz));
			else {
				string24 tmp;
				tmp.resize_no_zero_initialise(sz);
				r = overflowStore.push_back(std::move(tmp));
				}
			return r->to_string_view();
			}
}
namespace stt
{
  void pageQueueBumpStorageOverflowCtr::swap (pageQueueBumpStorageOverflowCtr & other)
                                                                   { overflowStore.swap(other.overflowStore); }
}
namespace stt
{
  void pageQueueBumpStorageOverflowCtr::clear ()
                             { overflowStore.clear(); }
}
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_page_queue_bump_storage
#endif //STT_STL_IMPL_IMPL
// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// page_bump_allocator.hh
//

#ifndef LZZ_page_bump_allocator_hh
#define LZZ_page_bump_allocator_hh
#define LZZ_INLINE inline
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_page_bump_allocator
#define STT_STL_IMPL_DOUBLE_GUARD_page_bump_allocator
#define LZZ_OVERRIDE
// page_bump_allocator.cpp
//

#define LZZ_INLINE inline
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_page_bump_allocator
#endif //STT_STL_IMPL_IMPL
// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// bitmap_indexed_page_queue.hh
//

#ifndef LZZ_bitmap_indexed_page_queue_hh
#define LZZ_bitmap_indexed_page_queue_hh
#define LZZ_INLINE inline
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_bitmap_indexed_page_queue
#define STT_STL_IMPL_DOUBLE_GUARD_bitmap_indexed_page_queue
#define LZZ_OVERRIDE
// bitmap_indexed_page_queue.cpp
//

#define LZZ_INLINE inline
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_bitmap_indexed_page_queue
#endif //STT_STL_IMPL_IMPL
