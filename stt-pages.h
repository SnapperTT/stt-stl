// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// mt_page_allocator.hh
//

#ifndef LZZ_mt_page_allocator_hh
#define LZZ_mt_page_allocator_hh

#ifndef STT_TLS_WRAPPER
	#ifdef __WIN32
		#define STT_TLS_WRAPPER WindowsThreadLocalWrapper
		#define STT_WINDOWS_TLS 1
		#define STT_thread_local_PATL_Data int
		#define STT_DWORD DWORD
	#else
		#define STT_TLS_WRAPPER NativeThreadLocalWrapper
		#define STT_thread_local_PATL_Data thread_local PATL_Data
		#define STT_DWORD int
	#endif
#endif

namespace stt {
	struct PATL_Data;
	}
	
#include <mutex>
#include <atomic>
#define LZZ_INLINE inline
namespace stt
{
  struct PATL_Data;
}
namespace stt
{
  struct NativeThreadLocalWrapper
  {
    static STT_thread_local_PATL_Data * mData;
    PATL_Data * getTlsData ();
    void setTlsData (PATL_Data * ptr);
  };
}
namespace stt
{
  struct WindowsThreadLocalWrapper
  {
    STT_DWORD dwTlsIndex;
    WindowsThreadLocalWrapper ();
    ~ WindowsThreadLocalWrapper ();
    PATL_Data * getTlsData ();
    void setTlsData (PATL_Data * ptr);
  };
}
namespace stt
{
  class ThreadSafePageAllocator
  {
  public:
    static void initThreadLocalAllocators ();
    static void cleanupThreadLocalAllocators ();
    static PATL_Data * getThreadLocalAllocators ();
    static pageI * allocPage ();
    static void freePage (pageI * page);
    static void allocPages (pageI * * pages, uint32_t const nPages);
    static void freePages (pageI * * pages, uint32_t const nPages);
  };
}
namespace stt
{
  class BackendPagePool
  {
  public:
    pageTypeEnum mPageType;
    uint32_t batchSize;
    pageHeader * allocFreeList;
    std::mutex mMutex;
    std::atomic <pageHeader*> _list;
    BackendPagePool ();
    ~ BackendPagePool ();
    void freeAll ();
    void atomicMerge (pageHeader * _insert);
    pageHeader * atomicTake ();
    void bulkFetch (pageHeader * * store, uint32_t const nPages);
  };
}
namespace stt
{
  class ThreadLocalPagePool
  {
  public:
    pageHeader * freelist;
    pageTypeEnum mPageType;
    int nPagesInFreeList;
    int requestAmount;
    int maxFreeListAmount;
    ThreadLocalPagePool ();
    ~ ThreadLocalPagePool ();
    void allocPages (pageHeader * * pages, uint32_t const nPages);
    void freePages (pageHeader * * pages, uint32_t const nPages);
    void freePagesList (pageHeader * pagesLinkedList, uint32_t const knownCount = 0);
    void returnPagesToGlobalPool (pageHeader * returnList, uint32_t const nReturned);
  };
}
namespace stt
{
  struct PATL_Data
  {
    ThreadLocalPagePool pageAlloc;
    ThreadLocalPagePool jumboPageAlloc;
    PATL_Data ();
  };
}
namespace stt
{
  class ThreadSafePageAllocatorImpl
  {
  public:
    STT_TLS_WRAPPER mTls;
    BackendPagePool PageGlobalFreeList;
    BackendPagePool JumboGlobalFreeList;
    ThreadSafePageAllocatorImpl ();
    ~ ThreadSafePageAllocatorImpl ();
    static ThreadSafePageAllocatorImpl & get ();
    void initThreadLocalAllocators ();
    void cleanupThreadLocalAllocators ();
    PATL_Data * getThreadLocalAllocators ();
    void allocPages (pageI * * pages, uint32_t const nPages);
    void freePages (pageI * * pages, uint32_t const nPages);
    void allocJumboPages (pageI * * pages, uint32_t const nPages);
    void freeJumboPages (pageI * * pages, uint32_t const nPages);
    static void systemAllocate (pageTypeEnum const mPageType, uint32_t const nPagesTotal, uint32_t const nSplit, pageHeader * * groupA, pageHeader * * groupB);
    template <typename PAGE_TYPE>
    static void systemAllocate_impl (uint32_t const nPagesTotal, uint32_t const nSplit, pageHeader * * groupA, pageHeader * * groupB);
    static void systemFreeList (pageHeader * head);
  };
}
namespace stt
{
  LZZ_INLINE PATL_Data * NativeThreadLocalWrapper::getTlsData ()
                                       { return mData; }
}
namespace stt
{
  LZZ_INLINE void NativeThreadLocalWrapper::setTlsData (PATL_Data * ptr)
                                               { mData = ptr; }
}
namespace stt
{
  LZZ_INLINE PATL_Data * WindowsThreadLocalWrapper::getTlsData ()
                                       {
		#ifdef STT_WINDOWS_TLS
		return (PATL_Data*) TlsGetValue(dwTlsIndex);
		#else
		return NULL;
		#endif
		}
}
namespace stt
{
  LZZ_INLINE void WindowsThreadLocalWrapper::setTlsData (PATL_Data * ptr)
                                               {
		#ifdef STT_WINDOWS_TLS
		TlsSetValue(dwTlsIndex, ptr);
		#endif
		}
}
namespace stt
{
  template <typename PAGE_TYPE>
  void ThreadSafePageAllocatorImpl::systemAllocate_impl (uint32_t const nPagesTotal, uint32_t const nSplit, pageHeader * * groupA, pageHeader * * groupB)
                                                                                                                                     {
		// Group A & B are pointers to pointers, NOT arrays of pointers
		// allocates at least nPagesTotal, and returns (nSplit) into linked list groupA and the rest into linked list groupB
		pageHeader* ph[nPagesTotal];
		ph[0] = (pageHeader*) new PAGE_TYPE();
		for (uint i = 1; i < nPagesTotal; ++i) {
			ph[i] = (pageHeader*) new PAGE_TYPE();
			ph[i-1]->next = ph[i];
			}
		
		// are we splitting?
		if (nSplit > 0) {
			ph[nSplit-1]->next = NULL;
			*groupA = ph[0];
			*groupB = ph[nSplit];
			
			ph[0]->cachedWorkingEnd = ph[nSplit-1];
			ph[nSplit]->cachedWorkingEnd = ph[nPagesTotal-1];
			}
		else {
			*groupA = NULL;
			*groupB = ph[0];
			ph[0]->cachedWorkingEnd = ph[nPagesTotal-1];
			}
		}
}
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_mt_page_allocator
#define STT_STL_IMPL_DOUBLE_GUARD_mt_page_allocator
#define LZZ_OVERRIDE
// mt_page_allocator.cpp
//

#define LZZ_INLINE inline
namespace stt
{
  STT_thread_local_PATL_Data * NativeThreadLocalWrapper::mData;
}
namespace stt
{
  WindowsThreadLocalWrapper::WindowsThreadLocalWrapper ()
                                    {
		dwTlsIndex = 0;
		#ifdef STT_WINDOWS_TLS
		dwTlsIndex = TlsAlloc();
		if (dwTlsIndex == TLS_OUT_OF_INDEXES)
			stt_abort();
		#endif
		}
}
namespace stt
{
  WindowsThreadLocalWrapper::~ WindowsThreadLocalWrapper ()
                                     {
		#ifdef STT_WINDOWS_TLS
		TlsFree(dwTlsIndex);
		#endif
		}
}
namespace stt
{
  void ThreadSafePageAllocator::initThreadLocalAllocators ()
                                                {
		// MUST be called on thread startup!
		ThreadSafePageAllocatorImpl::get().initThreadLocalAllocators();
		}
}
namespace stt
{
  void ThreadSafePageAllocator::cleanupThreadLocalAllocators ()
                                                   {
		// MUST be called on thread end!
		ThreadSafePageAllocatorImpl::get().cleanupThreadLocalAllocators();
		}
}
namespace stt
{
  PATL_Data * ThreadSafePageAllocator::getThreadLocalAllocators ()
                                                     {
		return ThreadSafePageAllocatorImpl::get().getThreadLocalAllocators();
		}
}
namespace stt
{
  pageI * ThreadSafePageAllocator::allocPage ()
                                  {
		// Allocates a single pageI
		pageI* arr[1];
		ThreadSafePageAllocatorImpl::get().allocPages(&arr[0], 1);
		return arr[0];
		}
}
namespace stt
{
  void ThreadSafePageAllocator::freePage (pageI * page)
                                          {
		pageI* arr[1];
		arr[0] = page;
		ThreadSafePageAllocatorImpl::get().freePages(&arr[0], 1);
		}
}
namespace stt
{
  void ThreadSafePageAllocator::allocPages (pageI * * pages, uint32_t const nPages)
                                                                     { return ThreadSafePageAllocatorImpl::get().allocPages(pages, nPages); }
}
namespace stt
{
  void ThreadSafePageAllocator::freePages (pageI * * pages, uint32_t const nPages)
                                                                     { return ThreadSafePageAllocatorImpl::get().freePages(pages, nPages); }
}
namespace stt
{
  BackendPagePool::BackendPagePool ()
                          {
		mPageType = pageTypeEnum::PAGE_TYPE_UNSET;
		batchSize = 100;
		
		allocFreeList = NULL;
		_list = NULL;
		}
}
namespace stt
{
  BackendPagePool::~ BackendPagePool ()
                           {
		freeAll();
		}
}
namespace stt
{
  void BackendPagePool::freeAll ()
                       {
		// Takes all pages held here and deallocates them
		mMutex.lock();
		pageHeader* h = atomicTake();
		if (h) {
			if (allocFreeList)
				allocFreeList->appendList(h);
			else
				allocFreeList = h;
			}
		ThreadSafePageAllocatorImpl::systemFreeList(allocFreeList);
		allocFreeList = NULL;
		mMutex.unlock();
		}
}
namespace stt
{
  void BackendPagePool::atomicMerge (pageHeader * _insert)
                                              {
		// Adds @_insert to the atomic free list @this->_list
		
		// Remove head from atomic to working memory
		pageHeader* workingList = atomicTake();
		// _list is now NULL
		
		// merge the lists
		if (workingList) {
			_insert->appendList(workingList);
			workingList = _insert;
			}
		
		// replace NULL head with the working list
		pageHeader* nullList = NULL;
		if (!_list.compare_exchange_strong(nullList, workingList)) {
			// failed merge, this must have been due to pre-emption, re-merge
			atomicMerge(workingList);
			}
		}
}
namespace stt
{
  pageHeader * BackendPagePool::atomicTake ()
                                  {
		// Reads the value of @_list and replaces it with NULL
		pageHeader* workingList = _list.load();
		while (!_list.compare_exchange_weak(workingList, NULL));
		return workingList; 
		}
}
namespace stt
{
  void BackendPagePool::bulkFetch (pageHeader * * store, uint32_t const nPages)
                                                                  {
		// Yank off atomic list and merge the linked lists
		pageHeader* h = atomicTake();
		mMutex.lock();
		if (h) {
			if (allocFreeList)
				allocFreeList->appendList(h);
			else
				allocFreeList = h;
			}
		
		pageHeader* w = allocFreeList;
		uint32_t i = 0;
		for (i = 0; i < nPages && w->next; ++i) {
			store[i] = w;
			w = w->next;
			}
			
		const uint32_t nAllocated = i;
		if (w->next && i == nPages) {
			// cut the linked list here
			pageHeader* newHead = w->next;
			w->next = NULL;
			w->cachedWorkingEnd = NULL;
			newHead->cachedWorkingEnd = allocFreeList->cachedWorkingEnd;
			allocFreeList = newHead;
			mMutex.unlock();
			return;
			}
		
		// we have a parital linked list, we need system allocation
		pageHeader* remaining = NULL;
		pageHeader* leftovers = NULL;
		ThreadSafePageAllocatorImpl::systemAllocate(mPageType, batchSize + nPages - nAllocated, nPages - nAllocated, &remaining, &leftovers);
		
		for (; i < nPages; ++i) {
			store[i] = remaining;
			remaining = remaining->next;
			}
		
		// the entire free list has been consumed so we can dispose of it here
		allocFreeList = leftovers;		
		mMutex.unlock();
		}
}
namespace stt
{
  ThreadLocalPagePool::ThreadLocalPagePool ()
                              {
		freelist = NULL;
		mPageType = pageTypeEnum::PAGE_TYPE_UNSET;
		nPagesInFreeList = 0;
		
		requestAmount = 100;
		maxFreeListAmount = 200;
		}
}
namespace stt
{
  ThreadLocalPagePool::~ ThreadLocalPagePool ()
                               {
		freePagesList(freelist);
		freelist = NULL;
		}
}
namespace stt
{
  void ThreadLocalPagePool::allocPages (pageHeader * * pages, uint32_t const nPages)
                                                                   {
		uint32_t count = 0;
		while (freelist && count < nPages) {
			pages[count] = freelist;
			count++;
			freelist = freelist->next;
			}
		if (count < nPages) {
			// we are out of pages, request pages from TSPA (locking)
			const uint32_t want = requestAmount + nPages - count;
			pageHeader* localStore[want];
			
			if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
				ThreadSafePageAllocatorImpl::get().PageGlobalFreeList.bulkFetch(&localStore[0], want);
			else if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
				ThreadSafePageAllocatorImpl::get().JumboGlobalFreeList.bulkFetch(&localStore[0], want);
			else
				abort();
			
			
			uint32_t idx = 0;
			for (;count < nPages; ++count) {
				pages[count] = localStore[idx];
				++idx;
				}
			}
		}
}
namespace stt
{
  void ThreadLocalPagePool::freePages (pageHeader * * pages, uint32_t const nPages)
                                                                  {
		// assembles pages into a linked list, then adds to the freelist
		if (!nPages) return;
		for (uint32_t i = 0; i < nPages-1; ++i) {
			pages[i]->next = pages[i+1];
			}
		pages[nPages-1]->next = NULL;
		pages[0]->cachedWorkingEnd = pages[nPages-1];
		freePagesList(pages[0], nPages);
		}
}
namespace stt
{
  void ThreadLocalPagePool::freePagesList (pageHeader * pagesLinkedList, uint32_t const knownCount)
                                                                                       {
		// frees an already prepared linked list of pages
		// if the number of pages is not known then knownCount 
		uint32_t realKnownCount = knownCount;
		if (!realKnownCount) {
			pageHeader* tmp = pagesLinkedList;
			while (tmp) {
				tmp = tmp->next;
				realKnownCount++;
				}
			}
		nPagesInFreeList += realKnownCount;	
		
		pagesLinkedList->cachedWorkingEnd->next = freelist;
		pagesLinkedList->cachedWorkingEnd = freelist->cachedWorkingEnd;
		freelist = pagesLinkedList;
		
		if (nPagesInFreeList > maxFreeListAmount) {
			pageHeader* returnList = freelist->splitList(requestAmount);
			const uint32_t nReturned = nPagesInFreeList - requestAmount;
			returnPagesToGlobalPool(returnList, nReturned);			
			}
		}
}
namespace stt
{
  void ThreadLocalPagePool::returnPagesToGlobalPool (pageHeader * returnList, uint32_t const nReturned)
                                                                                       {
		nPagesInFreeList -= nReturned;
		// Return pages to main cache
		if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
			ThreadSafePageAllocatorImpl::get().PageGlobalFreeList.atomicMerge(returnList);
		else if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
			ThreadSafePageAllocatorImpl::get().JumboGlobalFreeList.atomicMerge(returnList);
		else
			abort();
		}
}
namespace stt
{
  PATL_Data::PATL_Data ()
                    {
		pageAlloc.mPageType = pageTypeEnum::PAGE_TYPE_NORMAL;
		jumboPageAlloc.mPageType = pageTypeEnum::PAGE_TYPE_JUMBO;
		}
}
namespace stt
{
  ThreadSafePageAllocatorImpl::ThreadSafePageAllocatorImpl ()
                                      {
		PageGlobalFreeList.mPageType = pageTypeEnum::PAGE_TYPE_NORMAL;
		JumboGlobalFreeList.mPageType = pageTypeEnum::PAGE_TYPE_JUMBO;
		}
}
namespace stt
{
  ThreadSafePageAllocatorImpl::~ ThreadSafePageAllocatorImpl ()
                                       {}
}
namespace stt
{
  ThreadSafePageAllocatorImpl & ThreadSafePageAllocatorImpl::get ()
                                                  {
		static ThreadSafePageAllocatorImpl Instance;
		return Instance;
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::initThreadLocalAllocators ()
                                         {
		mTls.setTlsData(new PATL_Data);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::cleanupThreadLocalAllocators ()
                                            {
		PATL_Data* r = ThreadSafePageAllocatorImpl::get().mTls.getTlsData();
		if (r) delete r;
		mTls.setTlsData(NULL);
		}
}
namespace stt
{
  PATL_Data * ThreadSafePageAllocatorImpl::getThreadLocalAllocators ()
                                              {
		return mTls.getTlsData();
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::allocPages (pageI * * pages, uint32_t const nPages)
                                                              {
		PATL_Data* LA = getThreadLocalAllocators();
		LA->pageAlloc.allocPages((pageHeader**) pages, nPages);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::freePages (pageI * * pages, uint32_t const nPages)
                                                             {
		PATL_Data* LA = getThreadLocalAllocators();
		LA->pageAlloc.freePages((pageHeader**) pages, nPages);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::allocJumboPages (pageI * * pages, uint32_t const nPages)
                                                                   {
		PATL_Data* LA = getThreadLocalAllocators();
		LA->jumboPageAlloc.allocPages((pageHeader**) pages, nPages);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::freeJumboPages (pageI * * pages, uint32_t const nPages)
                                                                  {
		PATL_Data* LA = getThreadLocalAllocators();
		LA->jumboPageAlloc.freePages((pageHeader**) pages, nPages);
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::systemAllocate (pageTypeEnum const mPageType, uint32_t const nPagesTotal, uint32_t const nSplit, pageHeader * * groupA, pageHeader * * groupB)
                                                                                                                                                              {
		// Group A & B are pointers to pointers, NOT arrays of pointers
		if (mPageType == pageTypeEnum::PAGE_TYPE_NORMAL)
			systemAllocate_impl<pageI>(nPagesTotal, nSplit, groupA, groupB);
		else if (mPageType == pageTypeEnum::PAGE_TYPE_JUMBO)
			systemAllocate_impl<jumboPageI>(nPagesTotal, nSplit, groupA, groupB);
		else
			abort();
		}
}
namespace stt
{
  void ThreadSafePageAllocatorImpl::systemFreeList (pageHeader * head)
                                                     {
		pageHeader* w = head;
		while (w) {
			pageHeader* n = w->next;
			delete w;
			w = n;
			}
		}
}
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_mt_page_allocator
#endif //STT_STL_IMPL_IMPL
// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// page_queue.hh
//

#ifndef LZZ_page_queue_hh
#define LZZ_page_queue_hh
#define LZZ_INLINE inline
namespace stt
{
  template <typename T, typename P = pageI>
  struct pageQueueImpl
  {
    P p;
    pageQueueImpl ();
    constexpr T * ptr ();
    constexpr T const * ptr () const;
    static constexpr size_t localCapacity ();
    uint32_t const localSize () const;
    void push_back (T const & t);
    void push_back_impl (T const & t, pageQueueImpl * head);
    T & get (uint32_t const localIndex);
    T const & get (uint32_t const localIndex) const;
    struct iterator
    {
      T * ptr;
      T * localEnd;
      pageQueueImpl * currentPage;
      uint32_t idx;
      typename pageQueueImpl <T,P>::iterator & operator ++ ();
      void incr_nonInline ();
      bool operator != (iterator const & other) const;
    };
  };
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE pageQueueImpl <T, P>::pageQueueImpl ()
                                       {
			p.ph.initToZero();
			static_assert(sizeof (pageQueueImpl<T,P>) == STT_PAGE_SIZE);
			static_assert(std::is_trivially_copyable<T>::value);
			}
}
namespace stt
{
  template <typename T, typename P>
  constexpr T * pageQueueImpl <T, P>::ptr ()
                                                    { return (T*) &p._data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  template <typename T, typename P>
  constexpr T const * pageQueueImpl <T, P>::ptr () const
                                                    { return (const T*) &p._data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  template <typename T, typename P>
  constexpr size_t pageQueueImpl <T, P>::localCapacity ()
                                                              { return P::capacity() / sizeof(T);  }
}
namespace stt
{
  template <typename T, typename P>
  uint32_t const pageQueueImpl <T, P>::localSize () const
                                                 { return p.ph.localSize; }
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::push_back (T const & t)
                                            {
			push_back_impl(t, this);
			}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::push_back_impl (T const & t, pageQueueImpl * head)
                                                                      {
			if (p.ph.cachedWorkingEnd) {
				return p.ph.cachedWorkingEnd->push_back_impl(t, head);
				}
			if (p.ph.localSize >= localCapacity()) {
				// page is full! allocate a new page
				#warning for existing page here
				pageQueueImpl* PN = p.ph.wrangleAllocator()->allocatePage(sizeof(P));
				PN->initToZero();
				p.ph.next = PN;
				head->p.ph.cachedWorkingEnd = PN;
				
				PN->p.ph.totalSize = p.ph.totalSize;
				PN->push_back(t);
				return;
				}
			ptr()[p.ph.localSize] = t;
			p.ph.localSize++;
			head->p.ph.totalSize++;
			}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE T & pageQueueImpl <T, P>::get (uint32_t const localIndex)
                                                         {
			if (localIndex >= p.ph.localSize)
				stt::error::array_out_of_bounds(localIndex, p.ph.localSize);
			return ptr()[localIndex];
			}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE T const & pageQueueImpl <T, P>::get (uint32_t const localIndex) const
                                                                     {
			if (localIndex >= p.ph.localSize)
				stt::error::array_out_of_bounds(localIndex, p.ph.localSize);
			return ptr()[localIndex];
			}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE typename pageQueueImpl <T,P>::iterator & pageQueueImpl <T, P>::iterator::operator ++ ()
                                                                                   {
				while (ptr == localEnd && currentPage)
					incr_nonInline();
				ptr++;
				}
}
namespace stt
{
  template <typename T, typename P>
  void pageQueueImpl <T, P>::iterator::incr_nonInline ()
                                              {
				currentPage = currentPage->next;
				ptr = currentPage->ptr();
				localEnd = ptr[currentPage->p.ph.localSize];
				}
}
namespace stt
{
  template <typename T, typename P>
  LZZ_INLINE bool pageQueueImpl <T, P>::iterator::operator != (iterator const & other) const
                                                                             { return ptr != other.ptr; }
}
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_page_queue
#define STT_STL_IMPL_DOUBLE_GUARD_page_queue
#define LZZ_OVERRIDE
// page_queue.cpp
//

#define LZZ_INLINE inline
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_page_queue
#endif //STT_STL_IMPL_IMPL
// This file is autogenerated. See look at the .lzz files in the src/ directory for a more human-friendly version
#ifndef LZZ_OVERRIDE
	#define LZZ_OVERRIDE override
#endif
// page.hh
//

#ifndef LZZ_page_hh
#define LZZ_page_hh
#ifndef STT_PAGE_HEADER_SIZE
	#define STT_PAGE_HEADER_SIZE 64
#endif
#ifndef STT_PAGE_SIZE
	#define STT_PAGE_SIZE 4096
#endif
#ifndef STT_JUMBO_PAGE_SIZE
	#define STT_JUMBO_PAGE_SIZE 65536
#endif

namespace stt {
	union pageI;
	class PageAllocator;
	}
	
#define LZZ_INLINE inline
namespace stt
{
  enum pageTypeEnum
  {
    PAGE_TYPE_NORMAL,
    PAGE_TYPE_JUMBO,
    PAGE_TYPE_UNSET
  };
}
namespace stt
{
  struct pageHeader
  {
    void * allocator;
    pageHeader * next;
    pageHeader * cachedWorkingEnd;
    uint32_t localSize;
    uint32_t totalSize;
    uint64_t useMask;
    uint64_t (_unused) [3];
    void initToZero ();
    void appendList (pageHeader * other);
    pageHeader * splitList (uint32_t const nPages);
    pageHeader * end ();
    pageHeader * endCounting (int & countOut);
  };
}
namespace stt
{
  union pageI
  {
    pageHeader ph;
    uint8_t (_data) [STT_PAGE_SIZE];
    constexpr void * ptr ();
    constexpr void const * ptr () const;
    static constexpr size_t capacity ();
    static constexpr pageTypeEnum getPageType ();
  };
}
namespace stt
{
  union jumboPageI
  {
    pageHeader ph;
    uint8_t (_data) [STT_JUMBO_PAGE_SIZE];
    constexpr void * ptr ();
    constexpr void const * ptr () const;
    static constexpr size_t capacity ();
    static constexpr pageTypeEnum getPageType ();
  };
}
namespace stt
{
  LZZ_INLINE void pageHeader::initToZero ()
                                         {
			allocator = NULL;
			next = NULL;
			cachedWorkingEnd = NULL;
			localSize = 0;
			totalSize = 0;
			useMask = 0;
			}
}
#undef LZZ_INLINE
#endif
#undef LZZ_OVERRIDE

////////////////////////////////////////////////////////////////////////

#ifdef STT_STL_IMPL
#ifndef STT_STL_IMPL_DOUBLE_GUARD_page
#define STT_STL_IMPL_DOUBLE_GUARD_page
#define LZZ_OVERRIDE
// page.cpp
//


namespace stt {
	static_assert(sizeof(pageHeader) <= STT_PAGE_HEADER_SIZE);
	}
#define LZZ_INLINE inline
namespace stt
{
  void pageHeader::appendList (pageHeader * other)
                                                   {
			// appends other to this list
			// assumes cachedWorkingEnd is a valid value for both this and other
			cachedWorkingEnd->next = other;
			cachedWorkingEnd = other->cachedWorkingEnd;
			}
}
namespace stt
{
  pageHeader * pageHeader::splitList (uint32_t const nPages)
                                                             {
			// assumes cachedWorkingEnd is a valid value for this
			// if this is too short then returns NULL
			pageHeader* w = this;
			uint32_t cnt = 1;
			while (w->next && (cnt < nPages)) {
				cnt++;
				w = w->next;
				}
			// w should now be the end of this list
			// and w->next should be the start of next
			if (!w) return NULL; // fail split
			if (!w->next) return NULL; // fail split
			
			pageHeader* r = w->next;
			r->cachedWorkingEnd = cachedWorkingEnd;
			w->next = NULL;
			cachedWorkingEnd = w;
			return r;
			}
}
namespace stt
{
  pageHeader * pageHeader::end ()
                                  {
			// manually traverses to the end
			pageHeader* w = this;
			while (w->next) { w = w->next; }
			return w;
			}
}
namespace stt
{
  pageHeader * pageHeader::endCounting (int & countOut)
                                                       {
			// manually traverses to the end, counts number of pages
			pageHeader* w = this;
			while (w->next) { countOut++; w = w->next; }
			return w;
			}
}
namespace stt
{
  constexpr void * pageI::ptr ()
                                                       { return &_data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  constexpr void const * pageI::ptr () const
                                                       { return &_data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  constexpr size_t pageI::capacity ()
                                                        { return STT_PAGE_SIZE - STT_PAGE_HEADER_SIZE;  }
}
namespace stt
{
  constexpr pageTypeEnum pageI::getPageType ()
                                                                 { return pageTypeEnum::PAGE_TYPE_NORMAL; }
}
namespace stt
{
  constexpr void * jumboPageI::ptr ()
                                                       { return &_data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  constexpr void const * jumboPageI::ptr () const
                                                       { return &_data[STT_PAGE_HEADER_SIZE]; }
}
namespace stt
{
  constexpr size_t jumboPageI::capacity ()
                                                        { return STT_PAGE_SIZE - STT_PAGE_HEADER_SIZE;  }
}
namespace stt
{
  constexpr pageTypeEnum jumboPageI::getPageType ()
                                                                 { return pageTypeEnum::PAGE_TYPE_JUMBO; }
}
#undef LZZ_INLINE
#undef LZZ_OVERRIDE
#endif //STT_STL_IMPL_DOUBLE_GUARD_page
#endif //STT_STL_IMPL_IMPL
